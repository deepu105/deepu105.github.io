
var documents = [{
    "id": 0,
    "url": "/404.html",
    "title": "404",
    "body": "404 Page does not exist!Please use the search bar at the top or visit our homepage! "
    }, {
    "id": 1,
    "url": "/categories",
    "title": "Categories",
    "body": ""
    }, {
    "id": 2,
    "url": "/comment-policy",
    "title": "Comment policy",
    "body": "Keep it civil aka don‚Äôt be a jerk: We‚Äôre going to get into the thick of a lot of heated discussions and that‚Äôs okay. These discussions often entail topics that we all personally care a lot about and will passionately defend. But in order for discussions to thrive here, we need to remember to criticize ideas, not people. ¬†¬†So, remember to avoid:  name-calling ad hominem attacks Responding to a post‚Äôs tone instead of its actual content.  knee-jerk contradictionComments that we find to be hateful, inflammatory, or harassing may be removed. If you don‚Äôt have something nice to say about another user, don‚Äôt say it. Treat others the way you‚Äôd like to be treated. Always strive to add value to every interaction and discussion you participate in: There are a lot of discussions that happen every day on Disqus. Before joining in a discussion, browse through some of the most recent and active discussions happening in the community, especially if you‚Äôre new there. ¬†¬†If you are not sure your post adds to the conversation, think over what you want to say and try again later. Keep it tidy: Help make moderators‚Äô lives easier by taking a moment to ensure that what you‚Äôre about to post is in the right place. That means:  don‚Äôt post off-topic comments or discussions don‚Äôt cross-post the same thing multiple times review any specific posting guidelines for the community check if another active discussion on your topic has already been postedIf you see something, say something: Moderators are at the forefront of combatting spam, mediating disputes and enforcing community guidelines and, so are you. ¬†¬†If you see an issue, contact the moderators if possible or flag any comments for review. If you believe someone has violated the Basic Rules, report it to Disqus by flagging the user‚Äôs profile. No Self-promotion A discussion or comment that contains only a link to your blog, a product, or your article on another site will almost always be removed. Choose Your (Curse) Words Wisely Comments that contain profanity are automatically held for moderator review before being posted. Depending on the context of the comment, it may be removed. Profanity used to insult, antagonize, or inflame will always be removed. Don‚Äôt Be a Jerk Personal attacks and harassment will not be tolerated. Sexist, racist, misogynist, homophobic, and broad, offensive generalizations about groups of people are simply not allowed. Comments or discussions written intentionally to provoke will also be removed. Don‚Äôt Copy and Paste If you didn‚Äôt write it, or haven‚Äôt properly cited the article you‚Äôre quoting, don‚Äôt post it. English Only We currently only support English-only discussions on Disqus channels. Non-English comments and discussions will be removed. Related: Guide to building community guidelines: "
    }, {
    "id": 3,
    "url": "/",
    "title": "Deepu K Sasidharan",
    "body": "                                             I'm a Software Designer by passion &amp; profession. I'm also the co-lead of JHipster.          My expertise includes solution ideation, visualization, and prototyping.          I code using various Languages like Java, JavaScript, TypeScript, Go, Python and so on.          I'm an open-source software aficionado and a technology advocate by passion.          I'm also passionate about developer experience and user experience.          I also love Astronomy, Quadcopters, and Robotics.          I have authored a book on JHipster and write frequently about Java, JavaScript, Go, CloudNative and so on.                                Book:                       Full Stack Development with JHipster.         Get it on        Packt,        Amazon and        Safari.                                               OSS projects:                                            JHipster Generator:                          A cool generator for Angular/React/VueJS + Spring stack                                                    Angular Clock:                          A beautiful responsive clock face and clock widget for angular JS.          Built in SVG                                                          JHipster Registry:                          Service Registry, based on Spring Cloud Netflix Eureka and Spring         Cloud Config                                                    JHipster Entity Audit Generator:                          A yeoman generator to enable entity audit in JHipster generated apps                                                          JDL Studio:                 An awesome online JDL editor and visualizer                                            JHipster Bootswatch Theme Generator:                          A yeoman generator to enable Bootswatch themes in JHipster generated         apps                                                          Angular Object Diff:                          An AngularJS plugin to generate and view object difference                                                    UML and Sequence Diagram Generator:                                  A sequence diagram generator using angularJS and an UML Diagram         Generator based on PlantUML. Experimental.                                                             Follow me on social media:                                                                                                                                                                              Featured posts:                                                                                                                                                                                                                                                                                                 My reflections on Golang                              :               Do I like Go? Yes. Would I use it for every use case I have? Definitely not. :                                                                                                                                                                       Deepu K Sasidharan                                12 Jul 2019 | 20 mins read                                                                                                                                                                                                                                                                                                                                                                                  My beautiful Linux development environment                              :               One of the questions that I get quite often after a conference talk is weirdly not about what I presented but about my Linux desktop. . . :                                                                                                                                                                       Deepu K Sasidharan                                16 Jun 2019 | 7 mins read                                                                                                                                                                                                                   "
    }, {
    "id": 4,
    "url": "/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ ‚Äúsitemap. xml‚Äù   absolute_url }}   "
    }, {
    "id": 5,
    "url": "/blogs/index.html",
    "title": "Blogs",
    "body": "  {{ site. name }}      {{ site. description }}         Featured:       {% for post in site. posts %}    {% if post. featured == true %}            {% include featuredbox. html %}          {% endif %}  {% endfor %}        All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 6,
    "url": "/blogs/page/2/index.html",
    "title": " - page 2",
    "body": "  {{ site. name }}      {{ site. description }}         Featured:       {% for post in site. posts %}    {% if post. featured == true %}            {% include featuredbox. html %}          {% endif %}  {% endfor %}        All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 7,
    "url": "/blogs/page/3/index.html",
    "title": " - page 3",
    "body": "  {{ site. name }}      {{ site. description }}         Featured:       {% for post in site. posts %}    {% if post. featured == true %}            {% include featuredbox. html %}          {% endif %}  {% endfor %}        All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 8,
    "url": "/static-site-generators-rundown-how-i-set-up-my-own-blog-with-jekyll/",
    "title": "Static Site Generators rundown - How I set up my own blog with Jekyll",
    "body": "2019/08/01 - Last month I decided to move my blogs from Medium to Dev. to, I have detailed the reasons in the below post. https://dev. to/deepu105/why-i-m-moving-away-from-medium-13ki A lot of people suggested in the comments to set up my own blog and cross-post to Dev. to instead of relying only on one platform and I completely agree with them. I was procrastinating setting up my own blog for quite some time now. Finally, I decided to do it and set up my own blog at https://deepu. js. org/blogs/ in the process I also updated my personal website to use the same platform. So when I decided to do this finally I had to choose a blogging platform and there were few requirements I was keen about which influenced my decision. Requirements:  The platform should support writing posts using Markdown with code syntax highlights I love the Dev community and hence wanted to cross-post everything to Dev. to as well without having to make any changes to the post. Means I would author once and publish to both my blog and Dev. This means some constraints/requirements     It should support customizable front matter so that I can align it with Dev   It should support the custom liquid tags used by Dev or I should be able to easily add those    I should be able to have custom pages for my personal website Should be open source and have a good stable community Should be theme-able, have plugins for SEO, search and so on Should be statically generated and reasonably fast Should be able to host using GitHub pages - This was an optional requirementThe options rundown: With these in mind, I started evaluating some of the popular options below. Jekyll: Pros:  I have experience with Jekyll since I built the new JHipster website using it Supports Markdown, Liquid tags and Front Matter Supports custom pages, themes, plugins and is statically generated Is OSS and has a vibrant community Can be hosted on GitHubCons:  I would have to build or find replacements for the custom Liquid tags used by Dev I don‚Äôt have much experience with Ruby and I‚Äôm not very familiar with the Ruby ecosystem Not the fastest among the options. Becomes slower as site size increasesHugo: Pros:  Is very fast I have extensive experience with Go and Go templates which would be helpful Supports Markdown and Front Matter Supports custom pages, themes and is statically generated Is OSS and has a vibrant community Can be hosted on GitHubCons:  Doesn‚Äôt support Liquid tags Doesn‚Äôt have plugins. The built-in options are enough for my requirements at the moment thoughVuePress: Pros:  Built with VueJS and me have good experience with JavaScript and quite familiar with Vue Supports Markdown and Front Matter Supports custom pages, themes, SEO, search and is statically generated Is OSS and has a vibrant community Can be hosted on GitHubCons:  Doesn‚Äôt support Liquid tags Doesn‚Äôt have plugins. The built-in options are enough for my requirements at the moment though Not geared towards blogging, but it‚Äôs possible to do it easily with some hackingGatsby: Pros:  Built with React and I have good experience with React Supports Markdown and Front Matter Supports custom pages, themes, plugins and is statically generated Is OSS and has a vibrant community Can be hosted on GitHubCons:  Doesn‚Äôt support Liquid tagsWordPress: Pros:  Have used it in the past and is a battle-tested solution Supports Markdown using plugins Supports custom pages, themes, plugins and can be statically generated using plugins Is OSS and has a vibrant community Can be hosted on GitHub with some workaroundsCons:  Doesn‚Äôt support Front Matter and Liquid tags Since most of my core requirements can only be achieved using plugins and workarounds it feels too clumsyThough I personally liked Hugo because of its speed, based on the above the most logical choice for me was Jekyll. Building a personal website and blog with Jekyll: Getting started: Setting up Jekyll is super easy, I followed the official guide and had a site up and running in minutes. The steps in order were as below  Install a full Ruby development environment Install Jekyll and bundler gems for my user - gem install jekyll bundler --user-install Create a new site - jekyll new DeepuKSasidharan --skip-bundle, skipped the bundle install as I want to install to a vendor folder Cd into the folder DeepuKSasidharan and install gems to a vendor folder - bundle install --path vendor/bundle --full-index Start server - bundle exec jekyll serve and go to http://localhost:4000Using a Theme: Up next was setting up a custom theme, since I really like the minimal design of Medium, I decided to use Mediumish Jekyll Theme so I did the below steps to switch to this. Steps 3-5 above can be skipped and instead step 2 from the below can be done directly as well.  Delete the folder DeepuKSasidharan we created above Clone the theme to this folder - git clone https://github. com/wowthemesnet/mediumish-theme-jekyll. git DeepuKSasidharan Cd into the folder DeepuKSasidharan and install gems to a vendor folder - bundle install --path vendor/bundle --full-index Customize the _config. yaml file with my own user details, Google Analytics, Disqus ID and so on     I had to update the exclude section to add vendor/ to it and to . gitignore as well   Updated the jekyll-paginate plugin to jekyll-paginate-v2 in the plugins section   Commented out the baseurl section    Start server - bundle exec jekyll serve and go to http://localhost:4000Customizations: So now I had a good looking website with an about page and blog up and running. I customized the look and feel a bit and changed the default page from blogs to about. You can check the source code at deepu105/deepu105. github. io Now the next challenge was to make sure I can author once and post to both my blog and Dev. to, this means I have to make sure the front matter supported by Dev. to also works on my blog and any custom Liquid tags from Dev I use in the blog needs to work on my site as well. The first part was easy, I just had to customize my sites includes and layouts to use cover_image instead of image and use the tag: [] syntax for tags. I also added support for Dev. to like series and read time with a custom ruby plugin. Adding custom liquid tags: In order to use Dev. to tags, first I tried if I can reuse them from Dev since its OSS, but it seems like they are heavily coupled with Rails and internal models to be extracted into Gems. I created a ticket asking for it as well. So decided to write my own Liquid tags in Ruby. I reused available OSS Liquid tags and customized them to work like the Dev. to ones in syntax and feature. I ended up creating the codesandbox, twitter, gist, link, speakerdeck and youtube tags. You can find them here. Probably will add more as I use them. This is not scalable and I would love to see the Dev. to tags published as Ruby gems. Publishing to GitHub: Now that I have a site up and running with markdown posts that work in both my blog and Dev. to without having to make any adjustments, I decided to publish this to my Github accounts Github pages. But there was an issue here. Github doesn‚Äôt allow running any custom Ruby code on GitHub pages, so I can‚Äôt just push to GitHub and get the site built and published so I decided to write a simple script to do the site generation on my machine from the source branch and push it to the master branch on GitHub. 12345678910111213141516171819202122232425262728293031323334353637#!/bin/bashrm -rf _siteif [ -z  $(git status --porcelain)  ]; then  echo  &gt;&gt;&gt; Working directory clean   TMP_LOC=/tmp/deepu. github. io  /bin/rm -rf _site  /bin/rm -rf $TMP_LOC  echo  &gt;&gt; Building site   bundle update listen  bundle exec jekyll build  echo  &gt;&gt; Move site to temp folder   mkdir --parents $TMP_LOC  mv _site/* $TMP_LOC  echo  &gt;&gt; Checkout and clean master   git checkout master  find -mindepth 1 -depth -print0 | grep -vEzZ '(temp(/|$)|vendor(/|$)|\. git(/|$)|/\. gitignore$)' | xargs -0 rm -rvf  echo  &gt;&gt; Move site form temp &amp; publish to GitHub   mv $TMP_LOC/* .   now=$(date)  git add --all  git commit -am  Updated site on $now   git push origin master --force  echo  $now: Published changes to GitHub   git checkout site_srcelse  echo  Working directory is not clean. Commit changes!   exitfiMy current workflow: So now that I have things in place, I author posts as markdown with a full front matter like below and publish on my blog first. Then I publish the same to Dev. to 12345678---title:  Static Site Generators rundown - How I set up my own blog with Jekyll published: falsedescription: Static Site Generators comparisontags: [showdev, ruby, Jekyll, blogging]cover_image:canonical_url: https://deepu. js. org/setting-up-a-blog-with-jekyll/---I‚Äôm not using the RSS import option in Dev as it uses the rendered blog and hence might need adjustments. I also set the canonical_url to my blog site. Future plans: There are some things that can be improved.  Use the Dev. to API to publish this direct from my publish script when I author a new post or make updates to an existing one.  Improve the link tag and add some more tags for GitHub.  Use local assets image for my own blog and generate the image URL for Dev. to when publishing.  Currently, all links point to Dev. to, make the link tag smart enough to point to my blog when published to my site(I don‚Äôt want my readers to switch between sites). This might be a bit hard since Dev. to links have a random suffix. So what do you think? If you have any suggestions on improvements or questions leave a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Cover image credit: Photo by Patrick Fore on Unsplash "
    }, {
    "id": 9,
    "url": "/functional-programming-in-java-for-beginners/",
    "title": "7 Functional programming techniques in Java - A primer",
    "body": "2019/07/30 - There is a lot of hype around functional programming(FP) and a lot of cool kids are doing it but it is not a silver bullet. Like other programming paradigms/styles, functional programming also has its pros and cons and one may prefer one paradigm over the other. If you are a Java developer and wants to venture into functional programming, do not worry, you don‚Äôt have to learn functional programming oriented languages like Haskell or Clojure(or even Scala or JavaScript though they are not pure functional programming languages) since Java has you covered and this post is for you. I‚Äôm not gonna dive into all functional programming concepts in detail, instead, I‚Äôm gonna focus on things that you can do in Java which are in line with functional programming concepts. I‚Äôm also not gonna discuss the pros and cons of functional programming in general. What is functional programming?: As per Wikipedia,  Functional programming is a programming paradigm‚Äîa style of building the structure and elements of computer programs‚Äîthat treats computation as the evaluation of mathematical functions and avoids changing-state and mutable data. Hence in functional programming, there are two very important rules  No Data mutations: It means a data object should not be changed after it is created.  No implicit state: Hidden/Implicit state should be avoided. In functional programming state is not eliminated, instead, its made visible and explicitThis means:  No side effects: A function or operation should not change any state outside of its functional scope. I. e, A function should only return a value to the invoker and should not affect any external state. This means programs are easier to understand.  Pure functions only: Functional code is idempotent. A function should return values only based on the arguments passed and should not affect(side-effect) or depend on global state. Such functions always produce the same result for the same arguments. Apart from these there are functional programming concepts below that can be applied in Java, we will touch upon these further down.  Higher-order-functions Closures Currying Recursion Lazy evaluations Referential transparencyUsing functional programming doesn‚Äôt mean its all or nothing, you can always use functional programming concepts to complement Object-oriented concepts, especially in Java. The benefits of functional programming can be utilized whenever possible regardless of the paradigm or language you use. And that is exactly what we are going to see. Functional programming in Java: So let us see how we can apply some of the functional programming concepts above in Java. We will be using Java 11 as it is the LTS version currently. First-class and higher-order functions: First-class functions(function as a first-class citizen) means you can assign functions to variables, pass a function as an argument to another function or return a function from another. Unfortunately, Java doesn‚Äôt support this and hence makes concepts like closures, currying and higher-order-functions less convenient to write. The closest to first-class functions in Java is Lambda expressions. There are also some built-in functional interfaces like Function, Consumer, Predicate, Supplier and so on under the java. util. function package which can be used for functional programming. A function can be considered as a higher-order-function only if it takes one or more functions as parameters or if it returns another function as a result. The closest to higher-order-functions we can get in Java is using Lambda expressions and built-in Functional interfaces. This is not the nicest looking way of doing higher-order-functions, but this is how it is in Java and its not that bad IMO. 12345678910111213141516171819202122232425262728public class HocSample {  public static void main(String[] args) {    var list = Arrays. asList( Orange ,  Apple ,  Banana ,  Grape );    // we are passing an array and an anonymous inner class instance of FnFactory as arguments to mapForEach method.     var out = mapForEach(list, new FnFactory&lt;String, Object&gt;() {      @Override      public Object execute(final String it) {        return it. length();      }    });    System. out. println(out); // [6, 5, 6, 5]  }  // The method takes an array and an instance of FnFactory as arguments  static &lt;T, S&gt; ArrayList&lt;S&gt; mapForEach(List&lt;T&gt; arr, FnFactory&lt;T, S&gt; fn) {    var newArray = new ArrayList&lt;S&gt;();    // We are executing the method from the FnFactory instance    arr. forEach(t -&gt; newArray. add(fn. execute(t)));    return newArray;  }  @FunctionalInterface // this doesn't do anything it is just informative.   public interface FnFactory&lt;T, S&gt; {    // The interface defines the contract for the anonymous class    S execute(T it);  }}Fortunately, can actually simplify the above example further using the built-in Function interface and using the lambda expression syntax. 1234567891011121314151617public class HocSample {  public static void main(String[] args) {    var list = Arrays. asList( Orange ,  Apple ,  Banana ,  Grape );    // we are passing the array and a lambda expression as arguments to mapForEach method.     var out = mapForEach(list, it -&gt; it. length());     // This can be further simplified to  mapForEach(list, String::length); , I'm writing the expanded version for readability    System. out. println(out); // [6, 5, 6, 5]  }  // The method takes an array and an instance of Function as arguments (we have replaced the custom interface with the built-in one)  static &lt;T, S&gt; ArrayList&lt;S&gt; mapForEach(List&lt;T&gt; arr, Function&lt;T, S&gt; fn) {    var newArray = new ArrayList&lt;S&gt;();    // We are executing the method from the Function instance    arr. forEach(t -&gt; newArray. add(fn. apply(t)));    return newArray;  }}Using these concepts along with lambda expressions we can write closures and currying like below 1234567891011121314151617181920212223242526272829public class ClosureSample {  // this is a higher-order-function that returns an instance of Function interface  Function&lt;Integer, Integer&gt; add(final int x) {    // this is a closure, i. e, a variable holding an anonymous inner class instance of the Function interface    // which uses variables from the outer scope    Function&lt;Integer, Integer&gt; partial = new Function&lt;Integer, Integer&gt;() {      @Override      public Integer apply(Integer y) {        // variable x is obtained from the outer scope of this method which is declared as final        return x + y;      }    };    // The closure function instance is returned here    return partial;  }  public static void main(String[] args) {    ClosureSample sample = new ClosureSample();    // we are currying the add method to create more variations    Function&lt;Integer, Integer&gt; add10 = sample. add(10);    Function&lt;Integer, Integer&gt; add20 = sample. add(20);    Function&lt;Integer, Integer&gt; add30 = sample. add(30);    System. out. println(add10. apply(5)); // 15    System. out. println(add20. apply(5)); // 25    System. out. println(add30. apply(5)); // 35  }}We can simplify this further with lambda expressions like below 123456789101112131415161718192021public class ClosureSample {  // this is a higher-order-function that returns an instance of Function interface  Function&lt;Integer, Integer&gt; add(final int x) {    // The lambda expression is returned here as closure    // variable x is obtained from the outer scope of this method which is declared as final    return y -&gt; x + y;  }  public static void main(String[] args) {    ClosureSample sample = new ClosureSample();    // we are currying the add method to create more variations    Function&lt;Integer, Integer&gt; add10 = sample. add(10);    Function&lt;Integer, Integer&gt; add20 = sample. add(20);    Function&lt;Integer, Integer&gt; add30 = sample. add(30);    System. out. println(add10. apply(5));    System. out. println(add20. apply(5));    System. out. println(add30. apply(5));  }}There are also many built-in higher-order-functions in Java for example here is the sort method from java. util. Collections 12345678List&lt;String&gt; list = Arrays. asList( Apple ,  Orange ,  Banana ,  Grape );// This can be simplified as  Collections. sort(list, Comparator. naturalOrder()); , I'm writing the expanded version for readabilityCollections. sort(list, (String a, String b) -&gt; {  return a. compareTo(b);});System. out. println(list); // [Apple, Banana, Grape, Orange]The Java stream API also provides many interesting higher-order-functions like forEach, map and so on. Pure functions: As we saw already a pure function should return values only based on the arguments passed and should not affect or depend on global state. It is possible to do this in Java except for some cases when there are checked exceptions involved. This is quite simple, take the below this is a pure function. It will always return the same output for the given input and its behavior is highly predictable. We can safely cache the method if needed. 123public static int sum(int a, int b) {  return a + b;}If we add an extra line in this function, the behavior becomes unpredictable as it now has a side effect that affects an external state. 1234567static Map map = new HashMap&lt;String, Integer&gt;();public static int sum(int a, int b) {  var c = a + b;  map. put(a +  +  + b, c);  return c;}So try to keep your functions pure and simple. Recursion: Functional programming favors recursion over looping. In Java, this can be achieved either by using the stream API or by writing recursive functions. Let us see an example for calculating the factorial of a number. I also ran a benchmark on these using JMH and mentioned the nanoseconds/operation below In traditional iterative approach: 1234567891011121314public class FactorialSample {  // benchmark 9. 645 ns/op  static long factorial(long num) {    long result = 1;    for (; num &gt; 0; num--) {      result *= num;    }    return result;  }  public static void main(String[] args) {    System. out. println(factorial(20)); // 2432902008176640000  }}The same can be done using recursion as below which is favored in functional programming. 12345678910public class FactorialSample {  // benchmark 19. 567 ns/op  static long factorialRec(long num) {    return num == 1 ? 1 : num * factorialRec(num - 1);  }  public static void main(String[] args) {    System. out. println(factorialRec(20)); // 2432902008176640000  }}The downside of the recursive approach is that it will be slower compared to an iterative approach most of the times(The advantage we are aiming for is code simplicity and readability) and might result in stack overflow errors since every function call needs to be saved as a frame to the stack. To avoid this tail recursion is preferred, especially when the recursion is done too many times. In tail recursion, the recursive call is the last thing executed by the function and hence the functions stack frame is not saved by the compiler. Most compilers can optimize the tail recursion code the same way iterative code is optimized hence avoiding the performance penalty. Java compiler, unfortunately, does not do this optimization :( Now using tail recursion the same function can be written as below, but Java doesn‚Äôt optimize this, though there are workarounds, still it performed better in benchmarks. 1234567891011121314public class FactorialSample {  // benchmark 16. 701 ns/op  static long factorialTailRec(long num) {    return factorial(1, num);  }  static long factorial(long accumulator, long val) {    return val == 1 ? accumulator : factorial(accumulator * val, val - 1);  }  public static void main(String[] args) {    System. out. println(factorialTailRec(20)); // 2432902008176640000  }}We can also use the Java stream library for recursion but its slower than normal recursion at the moment. 1234567891011public class FactorialSample {  // benchmark 59. 565 ns/op  static long factorialStream(long num) {    return LongStream. rangeClosed(1, num)        . reduce(1, (n1, n2) -&gt; n1 * n2);  }  public static void main(String[] args) {    System. out. println(factorialStream(20)); // 2432902008176640000  }}Consider using stream API or recursion when writing Java code for readability and immutability, but if performance is critical or if the number of iterations will be huge use standard loops. Lazy evaluation: Lazy evaluation or non-strict evaluation is the process of delaying evaluation of an expression until it is needed. In general, Java does strict evaluation but for operands like &amp;&amp;, || and ?: it does a lazy evaluation. We can utilize this to do lazy evaluations when writing java code. Take this example where Java eagerly evaluates everything. 1234567891011121314151617181920public class EagerSample {  public static void main(String[] args) {    System. out. println(addOrMultiply(true, add(4), multiply(4))); // 8    System. out. println(addOrMultiply(false, add(4), multiply(4))); // 16  }  static int add(int x) {    System. out. println( executing add ); // this is printed since the functions are evaluated first    return x + x;  }  static int multiply(int x) {    System. out. println( executing multiply ); // this is printed since the functions are evaluated first    return x * x;  }  static int addOrMultiply(boolean add, int onAdd, int onMultiply) {    return (add) ? onAdd : onMultiply;  }}This will produce the below output and we can see that both functions are executed always 123456executing addexecuting multiply8executing addexecuting multiply16We can use lambda expressions and higher-order-functions to rewrite this into a lazily evaluated version 1234567891011121314151617181920212223242526public class LazySample {  public static void main(String[] args) {    // This is a lambda expression behaving as a closure    Function&lt;Integer, Integer&gt; add = t -&gt; {      System. out. println( executing add );      return t + t;    };    // This is a lambda expression behaving as a closure    Function&lt;Integer, Integer&gt; multiply = t -&gt; {      System. out. println( executing multiply );      return t * t * t;    };    // Lambda closures are passed instead of plain functions    System. out. println(addOrMultiply(true, add, multiply, 4));    System. out. println(addOrMultiply(false, add, multiply, 4));  }  // This is a higher-order-function  static &lt;T, R&gt; R addOrMultiply(      boolean add, Function&lt;T, R&gt; onAdd,      Function&lt;T, R&gt; onMultiply, T t  ) {    // Java evaluates expressions on ?: lazily hence only the required method is executed    return (add ? onAdd. apply(t) : onMultiply. apply(t));  }}This outputs the below and we can see that only required functions were executed 1234executing add8executing multiply64Type system: Java has a strong type system and with the introduction of the var keyword it now also has pretty decent type inference. The only thing missing compared to other functional programming languages are case classes. There are proposals for value classes and case classes for future Java versions. Let‚Äôs hope they make it. Referential transparency: From Wikipedia:  Functional programs do not have assignment statements, that is, the value of a variable in a functional program never changes once defined. This eliminates any chances of side effects because any variable can be replaced with its actual value at any point of execution. So, functional programs are referentially transparent. Unfortunately, there are not many ways to limit data mutation in Java, however by using pure functions and by explicitly avoiding data mutations and reassignment using other concepts we saw earlier this can be achieved. For variables, we can use the final keyword which is a non-access modifier to avoid mutations by reassignments. For example, the below will produce an error at compilation 123final var list = Arrays. asList( Apple ,  Orange ,  Banana ,  Grape );list = Arrays. asList( Earth ,  Saturn );But this will not help when variables are holding references to other objects, for example, the below mutation will work irrespective of the final keyword. 1234final var list = new ArrayList&lt;&gt;();list. add( Test );list. add( Test 2 );final keyword allows the internal state of referenced variables to be mutated and hence from a functional programming perspective final keyword is useful only for constants and to catch reassignments. Data structures: When using functional programming techniques it is encouraged to use functional data types such as Stacks, Maps and Queues. Hence maps are better than arrays or hash sets in functional programming as data stores. Conclusion: This is just an introduction for those who are trying to apply some functional programming techniques in Java. There are lot more that can be done in Java and Java 8 added a lot of API to make it easy to do functional programming in Java, like the stream API, Optional interface, functional interfaces and so on. As I said earlier functional programming is not a silver bullet but it offers a lot of useful techniques for more understandable, maintainable and testable code. It can co-exist perfectly well with imperative and object-oriented programming styles. In fact, we all should be using the best of everything. This video from Venkat Subramaniam is a great resource to dive deep into functional programming in Java                         I hope you find this useful. If you have any question or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. "
    }, {
    "id": 10,
    "url": "/jhipster-microservices-with-istio-service-mesh-on-kubernetes/",
    "title": "How to set up Java microservices with Istio service mesh on Kubernetes",
    "body": "2019/07/23 - Originally published at Medium on 17-Nov-2018. This post has been updated since to work with the latest version of JHipster and Istio. Istio is the coolest kid on the DevOps and Cloud block now. For those of you who aren‚Äôt following close enough ‚Äî Istio is a service mesh for distributed application architectures, especially the ones that you run on the cloud with Kubernetes. Istio plays extremely nice with Kubernetes, so nice that you might think that it‚Äôs part of the Kubernetes platform. If you are still wondering, what the heck is a service mesh or Istio? then let‚Äôs have an overview of Istio. Istio: Istio provides the following functionality in a distributed application architecture:    Service discovery ‚Äî Traditionally provided by platforms like Netflix Eureka or Consul.     Automatic load balancing ‚Äî You might have used Netflix Zuul for this.     Routing, circuit breaking, retries, fail-overs, fault injection ‚Äî Think of Netflix Ribbon, Hytrix and so on.     Policy enforcement for access control, rate limiting, A/B testing, traffic splits, and quotas ‚Äî Again you might have used Zuul to do some of these.     Metrics, logs, and traces ‚Äî Think of ELK or Stack driver     Secure service-to-service communication  Below is the architecture of Istio. Istio architecture It can be classified into 2 distinct planes. Data plane: Is made of Envoy proxies deployed as sidecars to the application containers. They control all the incoming and outgoing traffic to the container. Control plane: It uses Pilot to manages and configure the proxies to route traffic. It also configures Mixer to enforce policies and to collect telemetry. It also has other components like Citadel, to manage security, and Galley, to manage configurations. Istio can also configure an instance of Grafana, Prometheus, Jaeger, and Kiali for Monitoring and Observability. You can use this or use your existing monitoring stack as well if you wish to do so. I hope this provides an overview of Istio, now let‚Äôs focus on the goal of this article. Preparing the Kubernetes cluster: First, let us prepare a Kubernetes cluster to deploy Istio and our application containers. Follow the instructions for anyone of the platforms you prefer. Prerequisites: We will be using Helm to install Istio on the Kubernetes cluster and kubectl for deploying the applications. Helm: The Kubernetes package manager. Install it. kubectl: The command-line tool to interact with Kubernetes. Install and configure it. Create a cluster on Azure Kubernetes Service(AKS): If you are going to use Azure, then install Azure CLI to interact with Azure. Install and login with your Azure account (you can create a free account if you don‚Äôt have one already). If not skip this section. First, let us create a resource group. You can use any region you like here instead of East-US. 1$ az group create --name eCommerceCluster --location eastusCreate the Kubernetes cluster: 1234567$ az aks create \ --resource-group eCommerceCluster \ --name eCommerceCluster \ --node-count 4 \ --kubernetes-version 1. 13. 7 \ --enable-addons monitoring \ --generate-ssh-keysThe node-count flag is important as the setup requires at least four nodes with the default CPU to run everything. You can try to use a higher kubernetes-version if it is supported, else stick to 1. 13 The cluster creation could take while so sit back and relax. üçπ Once the cluster is created, fetch its credentials to be used from kubectl by running the below command. It automatically injects the credentials to your kubectl configuration under ~/. kube/config 123$ az aks get-credentials \ --resource-group eCommerceCluster \ --name eCommerceClusterYou can view the created cluster in the Azure portal: Kubernetes cluster in AKS Run kubectl get nodes to see it in the command line and to verify that kubectl can connect to your cluster. Cluster Nodes Proceed to the Install and setup Istio section. Create a cluster on Google Kubernetes Engine(GKE): If you are going to use Google Cloud Platform(GCP) then install Gcloud CLI to interact with GCP. Install and login with your GCP account (you can create a free account if you don‚Äôt have one already). You can set a region and zone using below commands or you can pass the zone option while executing each command. 12$ gcloud config set compute/region europe-west1$ gcloud config set compute/zone europe-west1-bFirst, we need a GCP project, you can either use an existing project that you have or create a new one using GCloud CLI with below command: 1$ gcloud projects create jhipster-demo-deepuSet the project you want to use as the default project: 1$ gcloud config set project jhipster-demo-deepuNow let us create a cluster for our application with the below command: 1234$ gcloud container clusters create hello-hipster \  --cluster-version 1. 13 \  --num-nodes 4 \  --machine-type n1-standard-2The num-nodes and machine-type flags are important as the setup requires at least four nodes with a bigger CPU to run everything. You can try to use a higher cluster-version if it is supported, else stick to 1. 13. The cluster creation could take while so sit back and relax. üçπ Once the cluster is created, fetch its credentials to be used from kubectl by running the below command. It automatically injects the credentials to your kubectl configuration under ~/. kube/config 1$ gcloud container clusters get-credentials hello-hipsterYou can view the created cluster in the GCP GUI. Kubernetes cluster on GKE Run kubectl get nodes to see it in the command line and to verify that kubectl can connect to your cluster. Cluster Nodes Install and setup Istio: Install Istio on your local machine by following these steps: 123456789$ cd ~/$ export ISTIO_VERSION=1. 2. 2$ curl -L https://git. io/getLatestIstio | sh -$ ln -sf istio-$ISTIO_VERSION istio$ export PATH=~/istio/bin:$PATHFirst, create a role binding on the Kubernetes cluster for Istio. 1234$ kubectl create clusterrolebinding cluster-admin-binding \ --clusterrole=cluster-admin \ --user= $(gcloud config get-value core/account) Let us create a namespace for Istio. 1$ kubectl create namespace istio-systemNow let us install Istio on our Kubernetes cluster using the provided helm charts from Istio. 12345678910# Install the Istio CRDs$ helm template install/kubernetes/helm/istio-init --name istio-init --namespace istio-system | kubectl apply -f -# Run this to verify all CRDs are installed. It should output 23 for this version of Istio. $ kubectl get crds | grep 'istio. io\|certmanager. k8s. io' | wc -l# Install the Istio demo set up so that we get Grafana, Jaeger &amp; Kiali set up as well. # For production, use the Istio default setup. Refer https://istio. io/docs/setup/kubernetes/install/helm/$ helm template install/kubernetes/helm/istio --name istio --namespace istio-system \  --values install/kubernetes/helm/istio/values-istio-demo. yaml | kubectl apply -f -Wait for the pods to run, these will be deployed to the istio-system namespace. 1$ watch kubectl get pods -n istio-systemOnce the pods are in running status, exit the watch loop and run the below to get the Ingress gateway service details. This is the only service that is exposed to an external IP. 1234$ kubectl get svc istio-ingressgateway -n istio-systemNAME          TYPE      CLUSTER-IP   EXTERNAL-IPistio-ingressgateway  LoadBalancer  10. 27. 249. 83  35. 195. 81. 130If the istio-ingressgateway shows external IP as , wait a few minutes until an IP address has been assigned. The external IP is very important here, let us save this to an environment variable so that we can use it in further commands. 1234$ export \ INGRESS_IP=$(kubectl -n istio-system get svc \ istio-ingressgateway \ -o jsonpath='{. status. loadBalancer. ingress[0]. ip}')Now our Kubernetes cluster is ready for Istio. üéâ For advanced Istio setup options refer to https://istio. io/docs/setup/kubernetes/ Creating the microservice application stack: In one of my previous posts, I showcased how to create a full-stack microservice architecture using JHipster and JDL. You can read the post here if you want to learn more details about it. For this exercise, we will use the same application but we will not use the Eureka service discovery option we used earlier. Also, note that the store application is further split into Gateway and Product applications. Architecture: Here is the architecture of the microservice that we are going to create and deploy today. Microservice architecture with Istio It has a gateway application and three microservice applications. Each of them has its own database. You can see that each application has an Envoy proxy attached to the pod as a sidecar. Istio control plane components are also deployed to the same cluster along with Prometheus, Grafana, and Jaeger. The Ingress gateway from Istio is the only entry point for traffic and it routes traffic to all microservices accordingly. Telemetry is collected from all the containers running in the cluster, including the applications, databases, and Istio components. Compared to the architecture of the original application here, you can clearly see that we replaced the JHipster registry and Netflix OSS components with Istio. The ELK monitoring stack is replaced with Prometheus, Grafana and Jaeger configured by Istio. Here is the original architecture diagram without Istio for a quick visual comparison. Microservice architecture with Netflix OSS Application JDL: Let‚Äôs take a look at the modified JDL declaration. You can see that we have declared serviceDiscoveryType no here since we will be using Istio for that. 400: Invalid requestDeployment JDL: JHipster version 5. 7. 0 introduced support for deployment declaration straight in the JDL Towards the future of #JHipster, #ScaffoldingAsCodeCheck this out. Soon you will be able to define apps, entities and deployment options with a single JDL file and generate everything with a single command. Hopefully, we can demo this for @Devoxx https://t. co/u28cwaymfc &mdash; ùîªùïñùïñùï°ùï¶ ùïÇ ùïäùïíùï§ùïöùïïùïôùïíùï£ùïíùïü (@deepu105) October 28, 2018We have the below in our JDL which declares our Kubernetes deployment: 12345678910deployment { deploymentType kubernetes appsFolders [store, invoice, notification, product] dockerRepositoryName  deepu105  serviceDiscoveryType no istio true kubernetesServiceType Ingress kubernetesNamespace jhipster ingressDomain  35. 195. 81. 130. nip. io }The serviceDiscoveryType is disabled and we have enabled Istio support ‚Äî the Envoy sidecars are injected automatically for the selected applications. Istio routes are also generated for the applications automatically. The kubernetesServiceType is set as Ingress, which is very important as Istio can only work with an Ingress controller service type. For Ingress, we need to set the domain DNS and this is where the Istio ingress gateway IP is needed. Now we need a DNS for our IP. For real use-cases, you should map a DNS for the IP, but for testing and demo purposes we can use a wildcard DNS service like nip. io to resolve our IP. Just append nip. io to our IP and use that as the ingressDomain. Note: I was switching between multiple clusters while writing this article as I didn‚Äôt want to keep them running and hence my istio-ingressgateway IP might be different between samples and screenshots. Use the IP based on your own setup if you are running these samples. Generate the applications and deployment manifests: Now that our JDL is ready, let us scaffold our applications and Kubernetes manifests. Create a new directory and save the above JDL in the directory. Let us name it app-istio. jdl and then run the import-jdl command. 12$ mkdir istio-demo &amp;&amp; cd istio-demo$ jhipster import-jdl app-istio. jdlThis will generate all the applications and install the required NPM dependencies in each of them. Once the applications are generated the deployment manifests will be generated and some useful instruction will be printed to the console. Generation output Open the generated code in your favorite IDE/Editor and explore the code. Interim issues with generated code: There is a bug in the latest JHipster version which creates some incorrect URLs for Istio, let us correct those here until my PR for the issue is merged. Replace INGRESS_IP with the EXTERNAL-IP obtained earlier from kubectl get svc istio-ingressgateway -n istio-system in below commands.  In kubernetes/store/store-gateway. yml,     Change all occurrence of the URL store. jhipster&lt;INGRESS_IP&gt;. nip. io to store. jhipster&lt;INGRESS_IP&gt;. nip. io.    Change prefix: /invoice/ to prefix: /services/invoice/   Change prefix: /product/ to prefix: /services/product/   Change prefix: /notification/ to prefix: /services/notification/    In kubernetes/invoice/invoice-deployment. yml, kubernetes/product/product-deployment. yml, and kubernetes/notification/notification-deployment. yml, change the readinessProbe and livenessProbe URLs from /&lt;microservice name&gt;/management/health to /services/&lt;microservice name&gt;/management/health. Replace &lt;microservice name&gt; with invoice, product and notification respectively.  In kubernetes/istio/gateway/grafana-gateway. yml, change host URL occurrences from grafana. istio-system&lt;INGRESS_IP&gt;. nip. io to grafana. &lt;INGRESS_IP&gt;. nip. io.  In kubernetes/istio/gateway/jaeger-gateway. yml, change host URL occurrences from jaeger. istio-system&lt;INGRESS_IP&gt;. nip. io to jaeger. &lt;INGRESS_IP&gt;. nip. io.  In kubernetes/istio/gateway/kiali-gateway. yml, change host URL occurrences from kiali. istio-system&lt;INGRESS_IP&gt;. nip. io to kiali. &lt;INGRESS_IP&gt;. nip. io.  Update the URLs in logSummary function in kubernetes/kubectl-apply. sh to reflect the above. That is it. This won‚Äôt be required after the next release of jhipster. Deploy to Kubernetes cluster using Kubectl: Now let us build and deploy our applications. Run the . /gradlew bootJar -Pprod jibDockerBuild command in the store, product, invoice, and notification folders to build the docker images. Once the images are built, push them to your docker repo with these commands. Note to change the Docker hub id from deepu105 to your id. 1234567891011$ docker image tag store deepu105/store$ docker push deepu105/store$ docker image tag invoice deepu105/invoice$ docker push deepu105/invoice$ docker image tag notification deepu105/notification$ docker push deepu105/notification$ docker image tag product deepu105/product$ docker push deepu105/productOnce the images are pushed, navigate into the generated Kubernetes directory and run the provided startup script. (If you are on windows you can run the steps in kubectl-apply. sh manually one by one. ) 12$ cd kubernetes$ . /kubectl-apply. shRun watch kubectl get pods -n jhipster to monitor the status. Deployed applications: Once all the pods are in running status we can explore the deployed applications Application gateway: The store gateway application is the entry point for our microservices. Get the URL for the store app by running echo store. $INGRESS_IP. nip. io, we already stored the INGRESS_IP to environment variables while creating the Istio setup. Visit the URL in your favorite browser and explore the application. Try creating some entities for the microservices: Store gateway application Monitoring: Istio setup includes Grafana and Prometheus configured to collect and show metrics from our containers. Let‚Äôs take a look. Let us look at Grafana by visiting the provided URL. Get it by running echo grafana. $INGRESS_IP. nip. io: Grafana dashboard for the Store application Grafana uses the metrics scraped by Prometheus. By default, only Grafana is exposed to external IP and hence we will use kubectl port forwarding to set up a secure tunnel to Prometheus available on localhost:9090: 123$ kubectl -n istio-system \  port-forward $(kubectl -n istio-system get pod -l \  app=prometheus -o jsonpath='{. items[0]. metadata. name}') 9090:9090Prometheus dashboard Observability: Istio configures Jaeger for distributed tracing and Kiali for service observability. Let us take a look at them. Get the Jaeger URL by running echo jaeger. $INGRESS_IP. nip. io: Jaeger tracing dashboard You can make some requests in the application and find it in the tracing dashboard by querying for the service. Click on any request to see tracing details. Let us now look at Kiali. Get the URL by running echo kiali. $INGRESS_IP. nip. io, use the credentials user: admin, password: admin to log in: Kiali service graph Conclusion: Istio provides building blocks to build distributed microservices in a more Kubernetes-native way and takes the complexity and responsibility of maintaining those blocks away from you. This means you do not have to worry about maintaining the code or deployments for service discovery, tracing and so on. Istio documentation says  Deploying a microservice-based application in an Istio service mesh allows one to externally control service monitoring and tracing, request (version) routing, resiliency testing, security and policy enforcement, etc. , in a consistent way across the services, for the application as a whole. Werner Vogels (CTO of AWS) quoted at AWS Re:Invent  ‚ÄúIn the future, all the code you ever write will be business logic. ‚Äù Istio Service mesh helps to make that reality closer. This lets you worry only about the applications that you are developing and with JHipster that future is truly here and you just need to worry about writing your business logic. While this is great, it is not a silver bullet. Keep in mind that Istio is fairly new compared to other stable and battle-tested solutions like JHipster Registry (Eureka) or Consul and overall such architectures are suitable only for complex distributed applications. Also, another thing to keep in mind is the resource requirements. The same microservices with JHipster Registry or Consul can be deployed to a 2 node cluster with 1 vCPU and 3. 75 GB of memory per node in GCP while you need a 4 node cluster with 2 vCPUs and 7. 5 GB of memory per node for Istio enabled deployments. The demo profile from Istio, we used, doesn‚Äôt apply any request limits for resources, and by adding and tuning those, the minimum requirement could be reduced. But still, I don‚Äôt think you can get it as low as that is needed for the JHipster registry option. In a real-world use case, the advantages of not having to maintain the complex parts of your infra vs having to pay for more resources might be a decision that has to be taken based on your priorities and goals. A huge shout out to Ray Tsang for helping me figure out an optimal cluster size for this application originally. Also a huge thank you from myself and the community to both Ray and Srinivasa Vasu for adding the Istio support to JHipster. JHipster provides a great Kubernetes setup to start with which you can further tweak as per your needs and platform. The Istio support will improve further over time, but it‚Äôs still a great starting point especially to learn. To learn more about JHipster and Full stack development, check out my book ‚ÄúFull Stack Development with JHipster‚Äù on Amazon and Packt. There is a great Istio tutorial from Ray Tsang here. Devoxx 2018: I did a talk at Devoxx 2018 along with Julien Dubois doing the same demo and promised that I‚Äôd write a detailed blog about it. This blog was originally based on that. Had a wonderful time at #devoxx2018, sad that I had to leave early due to work commitments. Had 3 talks and 1 of them with my friend and the real hipster @juliendubois, all the talks were well received and I&#39;m grateful for all the positive feedback. Will write blogs about it soon &mdash; ùîªùïñùïñùï°ùï¶ ùïÇ ùïäùïíùï§ùïöùïïùïôùïíùï£ùïíùïü (@deepu105) November 15, 2018You can watch this video to see JHipster + Istio in action.                          Here are the slides on Speaker Deck.                                                 If you like JHipster don‚Äôt forget to give it a star on Github. If you like this article, please leave likes/comments. I hope to write more about Istio soon. You can follow me on Twitter and LinkedIn. "
    }, {
    "id": 11,
    "url": "/make-the-most-out-of-vscode/",
    "title": "My VS Code setup - Making the most out of VS Code",
    "body": "2019/07/17 - Visual Studio Code(I like the sound of VS Code better), I just love it. It is my primary IDE. I always loved lightweight editors over IDEs. Many years ago I was using Eclipse for development and Notepad++ with some plugins for all other lightweight stuff. Then I discovered sublime text and was using it for a while. I still was finding Eclipse too heavyweight when I was doing web development. Then came Brackets from Adobe. It was a fairly nice editor especially for web development and I started using it heavily for web development. But Brackets was bit slow back then on a large codebase. Then came Atom which revolutionized the NodeJS desktop application landscape by introducing the Atom shell which ultimately became Electron. So I switched to Atom and loved its slick interface and nice pluggable features. It became my primary editor for all web development. So Electron paved the way for VS Code and though at first, I was skeptical dues to the association with Visual Studio, I tried it out and was amazed by its speed and user experience. There was no turning back now. I slowly started using VS Code for most of my day to day development, except for Java which I was using IntelliJ by now. Fast forward now below are the editor/IDE I use for development.  VS Code: JavaScript, TypeScript, EJS, HTML, CSS, Golang, Python, Ruby, Shell, Docker, Kubernetes, Terraform and everything in between including writing this blog post.  IntelliJ Idea: Java, Scala, Kotlin (Though I use VS Code for minor edits and to read the code, etc) VIM: For quick edits from the command line. PluginsOf course VS Code makes all this possible by allowing the use of plugins and there is a lot to choose from. Here are the plugins that I personally use to work on the above-said languages. You can use the code --install-extension command to install them from the terminal. Language support: Based on the Languages you work with you can add syntax, utility and language support plugins for those. I use the below JavaScript/TypeScript/Web:  EJS language support - Adds EJS template support.      code --install-extension DigitalBrainstem. javascript-ejs-support     Close HTML/XML tag - Auto close HTML/XML tags.      code --install-extension Compulim. compulim-vscode-closetag     ESLint - Adds support for ESLint rules.      code --install-extension dbaeumer. vscode-eslint     TSLint - Adds support for TSLint rules.      code --install-extension ms-vscode. vscode-typescript-tslint-plugin     Prettier - Adds support for Prettier formatter.      code --install-extension esbenp. prettier-vscode     es-beautifier - Formats JS according to Eslint rules.      code --install-extension dai-shi. vscode-es-beautifier    Go:  Go - Adds rich language support for Golang.      code --install-extension ms-vscode. Go    JVM:  Language Support for Java - Adds Java language support.      code --install-extension redhat. java     Debugger for Java - Adds lightweight Java debugging support.      code --install-extension vscjava. vscode-java-debug     JHipster JDL - Adds syntax support for JHipster JDL files.      code --install-extension jhipster-ide. jdl    The Java support indeed is getting better and better, so I hope one day I can completely switch to VS Code. Announcing the Visual Studio Code Installer for #Java https://t. co/u6lyKW0xFS &mdash; Markus Eisele (@myfear) June 16, 2019Python:  Language Support for Python - Adds Python language support, linting and debugging support.      code --install-extension ms-python. python    Cloud, Container &amp; others:  Docker - Adds Docker support(view and manage containers) and support for Docker, docker-compose files.      code --install-extension ms-azuretools. vscode-docker     Jenkinsfile Support - Adds syntax highlighting support for Jenkinsfile‚Äôs.      code --install-extension secanis. jenkinsfile-support     Terraform - Adds support for Terraform files.      code --install-extension mauve. terraform     Markdown all in one - Full markdown support with live preview, keyboard shortcuts, etc.      code --install-extension yzhang. markdown-all-in-one     PlantUML - Rich PlantUML support with live preview.      code --install-extension jebbs. plantuml     Visual Studio IntelliCode - Adds AI assisted intellisense support for multiple languages.      code --install-extension VisualStudioExptTeam. vscodeintellicode     YAML - Adds YAML support.      code --install-extension redhat. vscode-yaml    Theme: Dark++ Italic: My default theme. Similar to VS Code default dark theme but has support for FiraCode and Operator Mono fonts. I personally use FiraCode.  code --install-extension idbartosz. darkpp-italic Material icon theme: A nice icon theme based on material icons.  code --install-extension PKief. material-icon-theme Peacock: Subtly changes the workspace color of your workspace. Helpful to identify when you have many windows open.  code --install-extension johnpapa. vscode-peacock Tools: Auto rename tag: Automatically rename paired HTML/XML tags  code --install-extension formulahendry. auto-rename-tag Bracket pair colorizer 2: Marks matching bracket pairs with unique colors. This really makes reading code nicer  code --install-extension CoenraadS. bracket-pair-colorizer-2 Change case: Convert between different case. Trust me this is so handy  code --install-extension wmaurer. change-case Code spell checker: Fairly useful for spell checking within code. Takes cameCase etc into account  code --install-extension streetsidesoftware. code-spell-checker Easy snippet maker: Useful to store re usable snippets.  code --install-extension tariky. easy-snippet-maker EditorConfig for VS Code: Add support for EditorConfig.  code --install-extension EditorConfig. EditorConfig Git History: Enable viewing Git history within VS Code.  code --install-extension donjayamanne. githistory Gitignore: Makes it easy to work with . gitignore files.  code --install-extension codezombiech. gitignore Hide gitignored: Hides patterns defined in . gitignore from the editors explorer.  code --install-extension npxms. hide-gitignored Mark as excluded: Exclude stuff right from the explorer tree.  code --install-extension jcmordan. mark-as-excluded Toggle Excluded Files: Easily toggle between showing and hiding excluded files/folders.  code --install-extension eamodio. toggle-excluded-files IntelliJ IDEA Keybindings: I have bad muscle memory so wanted to use the same keyboard shortcuts as IntelliJ. There are mappings available for Sublime, Atom and so on.  code --install-extension k--kato. intellij-idea-keybindings Sort JSON: Sorts JSON object keys.  code --install-extension richie5um2. vscode-sort-json Test Explorer UI: Adds an explorer panel for running tests. Supports multiple languages and testing frameworks.  code --install-extension hbenl. vscode-test-explorer Todo Tree: Aggregate TODO, FIXME, etc in a tree view in explorer.  code --install-extension Gruntfuggly. todo-tree Terminal setupIf you are using Zsh shell with Oh-my-zsh like me as explained here, you might want to do the below to get the same terminal experience in the integrated VSCode terminal as well.  Follow these steps  Download and install a patched font.  On Linux, run fc-cache -f -v to refresh font cache.  On VSCode, open Preferences ‚Üí Settings and click on the {} icon to open JSON mode and set the below  123456  terminal. integrated. shell. linux :  /usr/bin/zsh ,  terminal. integrated. fontFamily :  'SauceCodePro Nerd Font Mono','Source Code Pro' ,  terminal. integrated. rightClickCopyPaste : true,  terminal. integrated. fontSize : 14,  terminal. integrated. cursorStyle :  underline ,  terminal. integrated. cursorBlinking : true    Replace linux with osx if you are on a Mac.  ConclusionThis might seem like too many plugins but on my configuration VS Code is lightning fast and loads up immediately and is faster then IntelliJ to load and work with. The beauty of VS Code is that you don‚Äôt need all the plugin all the time, you can disable the ones not required per workspace to make it even faster. Many people ask me why I use VS Code when I have IntelliJ and my answer have been always the same. IntelliJ is great but its also quite heavy. While all those advanced features are needed for Java, Scala or Kotlin development, VS Code is perfectly capable of giving a nice developer experience for lightweight languages like JS, TS, Go, Python, Rust, Ruby, etc. As a regular user of both IntelliJ and VS Code, I prefer VS Code as much as possible. The user experience is much nicer for my taste. In fact, I like the developer experience in VS Code better for JavaScript, TypeScript, Web, Python, and Golang. Also switching between them for JVM projects and others don‚Äôt feel weird for me as I have same keyboard mappings for both. The only time I fire up IntelliJ these days are when I want to do full-fledged Java development. For everything else, I use VS Code. I hope you find this useful. If you have any question or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. "
    }, {
    "id": 12,
    "url": "/reflection-on-golang/",
    "title": "My reflections on Golang",
    "body": "2019/07/12 - Do I like Go? Yes. Would I use it for every use case I have? Definitely not. Having worked on most of these said languages I won&#39;t choose Go for general purpose atleast not current version of Go, may be 2. 0 has more potential. &mdash; ùîªùïñùïñùï°ùï¶ ùïÇ ùïäùïíùï§ùïöùïïùïôùïíùï£ùïíùïü (@deepu105) March 7, 2019Don‚Äôt get me wrong, I like Go for what it is but like every other programming language, it is always a love-hate relationship. No programming language is perfect and all of them have their own merits and use cases. I hate it when I see people overusing something and I see that pattern with Go these days. To be fair, I have done my fair share of overusing in my career as well (mostly with JavaScript) and I can see why people do it. This is not gonna be a blog bashing Go or praising Go, it is just what I think of it after using it for over 9 months. Before I start a rant on the good and bad of Go, here is some background. After being in the tech industry for over 10 years, I would like to think of myself as a pragmatic programmer or at least as someone getting closer to that - that should be a programmer‚Äôs Nirvana. I didn‚Äôt even plan to be a programmer, if you ask the 18-year-old self of me, he would say that he wanted to be an astrophysicist or a robotics engineer(Yes building space robots was my dream). Like most teenage dreams, it didn‚Äôt happen and I ended up in tech instead. Though landing an IT Job was an accident, programming wasn‚Äôt alien to me. I did learn some C/C++ when I was in high school to help my girlfriend with her project and did dabble in some PHP, JavaScript, HTML and Flash(ActionScript) during my early college years for personal projects and blogs. So when I got a real IT job without having an IT background, I did what many in that situation did, I started learning the language that I stumbled upon first based on the task I was given, which happened to be Java. Being a quick learner and having some idea of programming concepts from C/C++ Java wasn‚Äôt that hard to learn and I was a pretty decent Java programmer in a few months. Then I was tasked with building some Web UI and I dived deep into the world of HTML, CSS, and JavaScript and honestly fell in love with JavaScript due to its flexibility and ease. I mastered JQuery and soon become the go-to guy for front end stuff in the office. I was anything but pragmatic back then, I was preaching JavaScript to everyone and would vehemently debate anyone who thought JS was a bad language. Fast forward to now and if I look back I have done projects in C/C++, PHP, JavaScript, TypeScript, HTML, CSS, Java, Groovy, Scala, Python and recently Go. I think this exposure probably helped me become more pragmatic as I have started to look at programming languages as tools and each of them has their own strengths and weaknesses. Well, there is more to this story but that‚Äôs for another time, the point is to set a baseline for the below reflections so that I don‚Äôt sound like someone just trying Go and going on a rant. Go is the latest language I learned and worked with, I have worked on a CLI project built with Go for over 9 months now, building a powerful scaffolding engine with my team(Yes, pretty much like JHipster) that uses Go templates where you could create what we call blueprints at XebiaLabs. So yes I have done much more than a hello world app with Go. Without wasting more time on unrelated things here is what I like about Go and what I don‚Äôt like. What I like about Go: Simplicity: I like the fact that Go is a simple language(Going through the entire language features on the tour page literally takes 15 minutes unless you do the exercises) and unlike Scala, Rust or even JavaScript Go doesn‚Äôt have many ways of doing the same thing which is extremely valuable for people working in teams and companies wanting to write maintainable code where even a newly joined employee can read and understand the code without needing much help. I think this is one of the biggest reason that is driving Go adoption. If you have worked on large scale projects you know how difficult it is when the code is unreadable and every new team member have to spend so much time trying to understand what a piece of code does. So I was really happy when I saw that Go doesn‚Äôt have features that rely heavily on implicit and such. The language features and concepts are easy to grasp and you can start being productive in Go quite soon. The only concepts that might seem bit complex are the concurrency part and even that is simpler compared to other languages. Language provided code style and vetting: This is such a time saver. IMO every language should just do this so that you don‚Äôt waste time debating code style and setting up lint rules. Go provides opinionated formatting, linting &amp; vet tool as part of the package and the Go compiler even enforces things like unused variable and stuff. Most of the IDE/Editor plugins also use these tools for formatting and linting and hence helps to keep consistent code style across Go projects which again adds to readability and maintenance. Goroutines &amp; Channels: This is one of the biggest strength of Go. The native support for concurrency and parallelism. This makes Go an ideal candidate for applications that require heavy concurrent and/or parallel processing, networking and so on. Goroutines makes it so easy to start lightweight threads and channels provide a way to communicate between these threads acting like a message bus. 1234567891011func main() {	messages := make(chan string)	collected := make([]string, 2)	go func() { messages &lt;-  ping  }()	go func() { messages &lt;-  pong  }()	collected = append(collected, &lt;-messages)	collected = append(collected, &lt;-messages)	fmt. Println(collected) // [ pong ping ]}Closures &amp; callbacks: If you have used JavaScript you would know how useful closures and callbacks are. Go like JavaScript treats functions as objects and hence can be assigned to variables, stored in maps, passed as function parameters and returned from functions. It also supports creating nested closures and anonymous functions which helps to encapsulate context. The behavior is pretty much similar to JavaScript. So you can apply some functional programming concepts in Go as well. 123456789101112131415161718192021222324func main() {	// an unnecessarily complicated example	type fnType = func(a int, b int) int	fnMap := map[string]fnType{		 ADD : func(a int, b int) int {			return a + b		},		 SUB : func(a int, b int) int {			return a - b		},	}	// this is a closure	localFn := func(method string) fnType {		return fnMap[method] // returns a function	}	printer := func(fn func(method string) fnType, method string) {		fmt. Println(fn(method)(10, 5)) // callback	}	// function passed as parameter	printer(localFn,  ADD )	printer(localFn,  SUB )}Type assertion and switches: Go provides a nice way of asserting types and can be used with a switch statement which makes it easier to do reflection and such. Multiple returns: This is quite a handy feature like in Python, we are used to deconstructing objects/arrays to achieve this in JavaScript and using Tuples and such in some languages. The returns can also be named which is nice for readability. Tooling: The in-code test coverage highlight in VsCode for @golang is slick. This is the best way to ensure you have good coverage@code pic. twitter. com/nk8iMwenCz &mdash; ùîªùïñùïñùï°ùï¶ ùïÇ ùïäùïíùï§ùïöùïïùïôùïíùï£ùïíùïü (@deepu105) February 14, 2019As mentioned earlier Go provides standard tooling for formatting, linting and so on and the language design makes it easy to build tooling for Go and hence editors/IDE has nice features like test generation, code coverage and so on. For example, the VSCode integration for Go provides the below options which helps with consistency and less boilerplate to write by hand.  Doesn‚Äôt need a runtime: Go doesn‚Äôt need a runtime like JVM or NodeJS, Go applications can be compiled into an executable cross-platform binary using the standard Go tooling. This makes Go applications portable and platform-independent. What I don‚Äôt like about Go: Simplicity: This is where the love-hate relationship starts, Go is a simple language which is nice but at times it feels too simple &amp; verbose and coming from Java/JavaScript ecosystem you are spoiled with some nice features &amp; syntax sugars which IMO makes the code more expressive and helps to keep it DRY. The things that I miss the most are  Generics: This is currently being considered in the next major iteration of Go, but until then this just makes you repeat code unnecessarily. I have lost count of the number of times I had to repeat the same block of code for different types where Generics would have kept it nice and simple. This is also one reason you don‚Äôt see libraries like Lodash for Go.  Standard error handling: This also seems to be coming in the next major iteration of Go but until it lands I can complain. Anyone writing Go will remember doing if err != nil uncountable times in your code. Removing those might cut the codebase in size by at least 20% Default values: Would love to see this in Go, this is quite useful. Maybe I‚Äôm just spoiled by JS. Too much boilerplate(not suitable for DRY): Go being too simple means you would have to write a lot of code as the language doesn‚Äôt offer constructs like map, reduce, and so on, and add the lack of generic on top means you would end up writing a lot of utility code and a lot of that will be repeated to accommodate different types. Imagine writing a map function in Go, you would have to write one for every combination of Map that can be used. These factors don‚Äôt make it easy to do DRY programming in Go. Dependency management: The dependency management in the Go ecosystem feels immature and too basic compared to other mainstream languages. Importing packages from Git is nice but it also makes it more fragile. What can go wrong when you are depending on a Git branch on your production application right! There is no way to use relative dependencies(Can‚Äôt beat NPM link!). These problems are similar to the issues with dependency range in Node package managers. Glide seems to be a popular choice but still is not as mature as solutions in other languages. In the project, I work on we used Gradle along with Gogradle and though it works fine the developer experience is not as good as using Gradle/Maven for Java project or using NPM on a NodeJS project. Source code in GOPATH: Go recommends you to create your Go projects under the GOPATH. Maybe it is just me, but I hate this as I would normally like to organize my code. For example, I have a ~/workspace/ folder where I organize my projects by the organization. If I follow the Go recommendation I have to put the project under /home/deepu/go/src along with all the library source code that is downloaded. If you don‚Äôt follow this then most of the Go tooling just doesn‚Äôt work. Currently, I have a specific Gradle task that copies over all the vendor libs to my local Gopath inside ~/workspace/XL/&lt;project&gt; to workaround this. Confusing pointer behaviors: Go has pretty good pointer support and the default behavior is to pass an object by value. If you want to pass something by reference you have to mark it specifically. But this behavior is not very consistent as the content of Maps and Slices by default are passed by reference and hence this could be a bit surprising to beginners. Struct hell: This is more of a nitpick. Structs are what you would use to create data structures in Go. It might look like an object but they are not exactly objects. While structs are fine functionally, in many cases you will end up with structs that look like the ugly brother of JSON. In real-world projects, you always will end up creating complex structs, especially if the application is doing some generic json or yaml parsing and soon your code will start to look like this. This is not that big of a concern but it just hurts my eyes every time I debug something or write tests. 123456789101112131415161718192021222324252627282930313233343536373839	func main() {	type MyYamlDoc struct {		foo []map[interface{}][]map[interface{}]interface{}		bar interface{}	}	ohno := MyYamlDoc{		[]map[interface{}][]map[interface{}]interface{}{			{				 Foo : {					{ Bar : map[interface{}][]map[interface{}]interface{}{						 Foo : {							{ Bar : map[interface{}][]map[interface{}]interface{}{								 Foo : {									{ Bar : map[interface{}][]map[interface{}]interface{}{										 Foo : {											{ Bar : map[interface{}][]map[interface{}]interface{}{}},										},									}},								},							}},						},					}},				},			},			map[interface{}][]map[interface{}]interface{}{				 Foo : {					{ Bar : map[interface{}][]map[interface{}]interface{}{}},				},			},		},		map[interface{}][]map[interface{}]interface{}{			 Foo : {				{ Bar : map[interface{}][]map[interface{}]interface{}{}},			},		},	}	fmt. Println(ohno)}Weird interface construct: The interface concept in Go is weird. These are the only implicit construct in Go. If you come from other languages that have interfaces then this will feel weird. The fact that they are implicit means its really easy to mess things up. Refactoring is messy unless you have a smart IDE, and you can accidentally implement someone‚Äôs interface by just naming your method a certain way. While implicit interfaces certainly help with polymorphism and decoupling code I personally would still prefer interfaces that are explicit. Another interface Gotcha is nil value checks, in Go, an interface is made up of two parts a type and a value, so an interface is nil only when both type and value are nil, this means you can‚Äôt just simply do nil checks on interfaces. This is so confusing the Go has a specific FAQ for this. Below article explains this in more detail https://dev. to/pauljlucas/go-tcha-when-nil‚Äìnil-hic Single GC algorithm: Go implements a concurrent tri-color mark-sweep collector as its garbage collector. This specific GC implementation is optimized for better pause times while ignoring program throughput, pause frequency and many other parameters that are considered during GC. Some people in the Go community claims this as the best ever GC. Having some Java background I would have to disagree as most JVM implementations provide multiple GC algorithms you can choose from which includes a concurrent mark-sweep collector as well and most of these are balanced to take care of many more parameters than just pause times. This articles analyses this in detail. So some use cases that produce a high amount of garbage might actually be slower in Go compared to another language due to frequent GC. Developer experience: This is purely based on personal experience and hence will vary from others. Being a polyglot developer who has worked with many languages, the developer experience from Go is not the best I have experienced. The DX of the JavaScript ecosystem is the best I have experienced so far. It feels like there are things missing in the Go ecosystem. Dependency management and toolchains need improvement. A bit more sensible language features and some syntax sugar wouldn‚Äôt hurt as well. Conclusion: Having worked with many major languages I can‚Äôt just use Go for every use case but I can see why people would use Go for every use-case out there if they haven‚Äôt worked with other languages. So where would I use Go?:  I would definitely use Go when the use case requires a lot of parallel processing and/or concurrency(both are not the same thing but are closer to each other) as you can make use of Goroutines for this and is much simpler and efficient than managing threads like in a Java application or working around it in JavaScript using callback hell since JS is actually single-threaded. Here is a nice article explaining the advantage of Goroutines.  Simple microservices where boilerplate is not a concern Networking applications or web servers, especially with async workloads, can greatly benefit from Go. But to be fair you can do these in Java, Python, JS, etc as well but Go in the end will provide better efficiency and would be easier to implement.  System programming. While Rust or C is a much better choice for this but if those are not in your arsenal then Go is the next best thing. With decent support for pointers and its standard library its easier for system programs than other mainstream languages. Many popular system tools like Docker, Kubernetes, etc are indeed written in Go. Where I wouldn‚Äôt use Go?:  Complex web application: I would choose Java with a framework like Spring or Micronaut as its much more maintainable and battle-tested and you would focus more on business logic than writing boilerplate infrastructure code. One common argument against this stack is its memory footprint but it is possible to get lower memory footprint with Spring and frameworks like Micronaut and Quarkus actually promises that OOB.  After writing a high-level CLI tool in Go, I hate the experience, I kept thinking that doing it in JavaScript would have been 10 times more productive and a nicer experience. SO I would choose JavaScript or TypeScript running on NodeJS for CLI tool any day. Mainly due to the ecosystem and the sheer joy and speed of getting things done without spending all your time writing boilerplate code. But this wouldn‚Äôt be applicable if the CLI in question a system tool or a networking tool, in those cases Go could be a good option. I do hope Go evolves into a general-purpose language over time and many of these concerns are solved. In the meantime, I‚Äôll try to follow this mantra. Remember this manthra &quot;right tools for the right job, right pattern for the use-case&quot; #engineering #development #architecture #microservices https://t. co/SA42jQ5TLH &mdash; ùîªùïñùïñùï°ùï¶ ùïÇ ùïäùïíùï§ùïöùïïùïôùïíùï£ùïíùïü (@deepu105) July 2, 2019But then you can always choose to fasten a screw using a hammer. Using the wrong tool for the job. #programming pic. twitter. com/5RdVqGuZoj &mdash; Rory Preddyü•ë (@rorypreddy) June 24, 2019If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Cover image credit: Image from Gophercises created by @joncalhoun, Marcus Olsson (@marcusolsson), and Jon Calhoun. "
    }, {
    "id": 13,
    "url": "/configure-a-beautiful-terminal-on-unix/",
    "title": "Configure a beautiful terminal on Unix with Zsh",
    "body": "2019/07/01 - I was a long time Windows user, a fairly happy one, but as a developer, there were a lot of things that were missing for me and one of the main was the terminal experience. I‚Äôm not a fan of the closed ecosystem of Apple so Linux was an easy choice for me and I switched to Linux almost 3 years ago. I did start out with Ubuntu and later switched to Fedora which is my primary OS now. You can read about my setup here As a senior developer and open source community lead, I spent a lot of time on the terminal and a terminal with a nice developer experience instantly makes you happier and more productive. The default bash terminal is good for beginners but if you really want a powerful terminal you need something more than bash. Let‚Äôs see how to configure a powerful and productive terminal experience. The setup is based on what I have configured on my Fedora machine. The same setup can be recreated on any other Linux distribution, BSD or Mac as well. You just need to use the installation instruction from the tools for the given platform.  Below are the tools we would need for this. Zsh: Zsh is one of the most feature-rich shells for Unix. It works on Linux, Mac, WSL, and BSD. There are alternatives like Fish which also offers similar features but I personally like Zsh.  Check if Zsh is already installed by running zsh --version on your terminal. If not found, install it using your package manager.      Fedora: sudo dnf install zsh   Mac: brew install zsh zsh-completions   RHEL/CentOS: sudo yum update &amp;&amp; sudo yum -y install zsh   Ubuntu/Debian: sudo apt install zsh   For other platform refer this    Now make Zsh your default shell by running chsh -s $(which zsh).  Log out and log in back again to use your new default shell.  Test that it worked with echo $SHELL. Expected result: /bin/zsh or similar.  Test with $SHELL --version. Expected result: zsh 5. 6. 2 or similarNote: If you have installed Zsh for the first time and launch the shell it would prompt you to configure some settings. You can choose to ignore that by hitting q as we will configure it later on. Oh-My-Zsh: Oh-My-Zsh gives the Zsh shell superpowers. Its a framework to manage Zsh configuration. It has plugins and themes for Zsh(A lot of them). From their Github page:  Once installed, your terminal shell will become the talk of the town or your money back! With each keystroke in your command prompt, you‚Äôll take advantage of the hundreds of powerful plugins and beautiful themes. Strangers will come up to you in caf√©s and ask you, ‚Äúthat is amazing! are you some sort of genius?‚Äù Just install it. You need it :) 1sh -c  $(curl -fsSL https://raw. githubusercontent. com/robbyrussell/oh-my-zsh/master/tools/install. sh) Terminal emulator/multiplexer: Optionally you can use a Terminal emulator that can manage windows and panes for you. For Linux I would recommend using Tilix, I have been using it for 3 years and its just amazing. For Mac, you can use iTerm2 which is very popular. Alternatively, you can also use tmux if you want something lighter on your existing Terminal app on Linux, BSD or Mac. Configuring Zsh: This is the fun part. Let us make the terminal awesome. Install plugins: First, let us install some additional plugins that are not bundled with Oh-My-Zsh. zsh-autosuggestions: Provides auto completion for shell commands. Run git clone https://github. com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/plugins/zsh-autosuggestions to install zsh-syntax-highlighting: Provides syntax highlighting on the shell. Run git clone https://github. com/zsh-users/zsh-syntax-highlighting. git ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/plugins/zsh-syntax-highlighting to install autojump: Provides a smarter directory navigation system. Install autojump for your OS following instructions here. Now let us configure the ~/. zshrc file with some settings. Here is my full . zshrc file. Your mileage may vary. Add exports: We will start with some exports. 1234567891011121314export TERM= xterm-256color  # This sets up colors properly# set shellexport SHELL=/usr/bin/zsh# If you come from bash you might have to change your $PATH. export NODE_PATH=$NODE_PATH:$HOME/. npm-global/lib/node_modulesexport JAVA_HOME=/usr/java/latestexport PATH=$JAVA_HOME/bin:~/. npm-global/bin:$HOME/bin:/usr/local/bin:$PATH# Add exports from your profilesource ~/. profile# Path to your oh-my-zsh installation. export ZSH=$HOME/. oh-my-zshZsh settings: Now we can configure some Zsh specific settings 1234DISABLE_MAGIC_FUNCTIONS=trueZSH_AUTOSUGGEST_MANUAL_REBIND=1COMPLETION_WAITING_DOTS=trueDISABLE_UNTRACKED_FILES_DIRTY=trueZsh theme: Now, Let‚Äôs set up a nice theme. I‚Äôm using powerlevel10k as my current theme and it‚Äôs fast and looks great. You can use the default or you can choose any theme you like from the list here. If you like my theme then follow these instructions. Thanks to Roman Perepelitsa for some cool tips Run git clone https://github. com/romkatv/powerlevel10k. git ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/themes/powerlevel10k to install the theme. Install a Powerline font. I use Adobe Source Code Pro Add the below configuration to the ~/. zshrc file. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182# Set name of the theme to load. Optionally, if you set this to  random # it'll load a random theme each time that oh-my-zsh is loaded. # See https://github. com/robbyrussell/oh-my-zsh/wiki/ThemesZSH_THEME= powerlevel10k/powerlevel10k ############ POWERLEVEL THEME SETTINGS ##############POWERLEVEL9K_MODE='awesome-fontconfig'POWERLEVEL9K_LEFT_PROMPT_ELEMENTS=(dir vcs nvm)POWERLEVEL9K_RIGHT_PROMPT_ELEMENTS=(disk_usage time)POWERLEVEL9K_PROMPT_ADD_NEWLINE=truePOWERLEVEL9K_PROMPT_ON_NEWLINE=truePOWERLEVEL9K_SHOW_RULER=truePOWERLEVEL9K_RULER_CHAR='‚îÄ'POWERLEVEL9K_RULER_BACKGROUND=nonePOWERLEVEL9K_RULER_FOREGROUND=237POWERLEVEL9K_LEFT_SEGMENT_END_SEPARATOR=POWERLEVEL9K_LEFT_SEGMENT_SEPARATOR=POWERLEVEL9K_LEFT_SUBSEGMENT_SEPARATOR=' 'POWERLEVEL9K_RIGHT_SEGMENT_END_SEPARATOR=POWERLEVEL9K_RIGHT_SEGMENT_SEPARATOR=POWERLEVEL9K_RIGHT_SUBSEGMENT_SEPARATOR=POWERLEVEL9K_WHITESPACE_BETWEEN_LEFT_SEGMENTS=POWERLEVEL9K_SHORTEN_DIR_LENGTH=2POWERLEVEL9K_SHORTEN_STRATEGY= truncate_middle POWERLEVEL9K_DIR_SHOW_WRITABLE=truePOWERLEVEL9K_DISK_USAGE_NORMAL_BACKGROUND=nonePOWERLEVEL9K_DISK_USAGE_WARNING_BACKGROUND=magentaPOWERLEVEL9K_DISK_USAGE_CRITICAL_BACKGROUND=redPOWERLEVEL9K_TIME_BACKGROUND=nonePOWERLEVEL9K_TIME_FOREGROUND=whitePOWERLEVEL9K_DIR_HOME_BACKGROUND=nonePOWERLEVEL9K_DIR_HOME_SUBFOLDER_BACKGROUND=nonePOWERLEVEL9K_DIR_ETC_BACKGROUND=nonePOWERLEVEL9K_DIR_DEFAULT_BACKGROUND=nonePOWERLEVEL9K_DIR_NOT_WRITABLE_BACKGROUND=nonePOWERLEVEL9K_DIR_HOME_FOREGROUND=bluePOWERLEVEL9K_DIR_HOME_SUBFOLDER_FOREGROUND=bluePOWERLEVEL9K_DIR_ETC_FOREGROUND=bluePOWERLEVEL9K_DIR_DEFAULT_FOREGROUND=bluePOWERLEVEL9K_DIR_NOT_WRITABLE_FOREGROUND=redPOWERLEVEL9K_OS_ICON_BACKGROUND= white POWERLEVEL9K_OS_ICON_FOREGROUND= blue POWERLEVEL9K_VCS_GIT_ICON='%fon %F{040}\uf1d3 'POWERLEVEL9K_VCS_GIT_GITHUB_ICON='%fon %F{040}\uf09b 'POWERLEVEL9K_VCS_GIT_BITBUCKET_ICON='%fon %F{040}\uf171 'POWERLEVEL9K_VCS_GIT_GIT_GITLAB_ICON='%fon %F{040}\uf296 'POWERLEVEL9K_VCS_CLEAN_BACKGROUND=nonePOWERLEVEL9K_VCS_UNTRACKED_BACKGROUND=nonePOWERLEVEL9K_VCS_MODIFIED_BACKGROUND=nonePOWERLEVEL9K_VCS_LOADING_BACKGROUND=nonePOWERLEVEL9K_VCS_CLEAN_FOREGROUND= 040 POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND= red POWERLEVEL9K_VCS_MODIFIED_FOREGROUND= yellow POWERLEVEL9K_VCS_LOADING_FOREGROUND= grey POWERLEVEL9K_VCS_UNTRACKED_ICON=$'%{\b?%}'POWERLEVEL9K_VCS_UNSTAGED_ICON=$'%{\b!%}'POWERLEVEL9K_VCS_STAGED_ICON=$'%{\b+%}'POWERLEVEL9K_DIR_NOT_WRITABLE_VISUAL_IDENTIFIER_COLOR=redPOWERLEVEL9K_LOCK_ICON=$'\uf023'POWERLEVEL9K_MULTILINE_FIRST_PROMPT_PREFIX=''local p='%F{%(?. green. red)}${${${KEYMAP:-0}:#vicmd}:+‚ùØ}${${$((!${#${KEYMAP:-0}:#vicmd})):#0}:+‚ùÆ}%f 'POWERLEVEL9K_MULTILINE_LAST_PROMPT_PREFIX= $p POWERLEVEL9K_NVM_BACKGROUND=nonePOWERLEVEL9K_NVM_FOREGROUND=greenPOWERLEVEL9K_NODE_ICON='%fvia %F{green}‚¨¢'############ END- POWERLEVEL THEME SETTINGS ##############Enable plugins: We can finish off by enabling the plugins and some tweaks 1234plugins=(zsh-autosuggestions git docker docker-compose autojump zsh-syntax-highlighting dnf npm)source $ZSH/oh-my-zsh. shAnd that‚Äôs it we are ready. Start a new terminal session and enjoy. Issues &amp; workarounds: If you use Tilix as your terminal emulator, then this might be required for proper pane splitting. Add this to your ~/. zshrc 123if [[ $TILIX_ID ]]; then    source /etc/profile. d/vte. shfiIf you are getting errors from the zsh-completion plugin, you might want to add this to the beginning of your ~/. zshrc 1234# workaround as per https://superuser. com/questions/1222867/zsh-completion-functions-brokenFPATH=$HOME/. oh-my-zsh/plugins/git:$HOME/. oh-my-zsh/functions:$HOME/. oh-my-zsh/completions:/usr/share/zsh/site-functions:/usr/share/zsh/$ZSH_VERSION/functionsexport FPATHIf you encounter an error from Oh-My-Zsh saying [oh-my-zsh] Insecure completion-dependent directories detected, set ZSH_DISABLE_COMPFIX=true right before the line source $ZSH/oh-my-zsh. sh in your ~/. zshrc file and restart your session or run exec zsh Dockerized playground. : If you have Docker installed then you can use the below snippet to try this setup in a sandbox without installing anything or affecting your existing setup. 123456789docker run -e LANG=C. UTF-8 -e LC_ALL=C. UTF-8 -e TERM=$TERM -it --rm ubuntu bash -uexc ' apt update &amp;&amp; apt install -y git curl zsh autojump &amp;&amp; cd /root sh -c  $(curl -fsSL https://raw. githubusercontent. com/robbyrussell/oh-my-zsh/master/tools/install. sh)  --skip-chsh --unattended git clone https://github. com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/plugins/zsh-autosuggestions git clone https://github. com/zsh-users/zsh-syntax-highlighting. git ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/plugins/zsh-syntax-highlighting git clone https://github. com/romkatv/powerlevel10k. git ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/themes/powerlevel10k curl -fsSLO http://bit. ly/Spaceship10kTheme echo  source ~/Spaceship10kTheme  &gt;~/. zshrc exec zsh'VSCode Tip: If you are using VSCode like me, you might want to do the below to get the same terminal experience in the integrated VSCode terminal as well.  Follow these steps  Download and install a patched font.  On Linux, run fc-cache -f -v to refresh font cache.  On VSCode, open Preferences ‚Üí Settings and click on the {} icon to open JSON mode and set the below  123456  terminal. integrated. shell. linux :  /usr/bin/zsh ,  terminal. integrated. fontFamily :  'SauceCodePro Nerd Font Mono','Source Code Pro' ,  terminal. integrated. rightClickCopyPaste : true,  terminal. integrated. fontSize : 14,  terminal. integrated. cursorStyle :  underline ,  terminal. integrated. cursorBlinking : true    Replace linux with osx if you are on a Mac.  I hope you like it. If you have any question or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. "
    }, {
    "id": 14,
    "url": "/must-have-gnome-plugins/",
    "title": "Must have GNOME extensions",
    "body": "2019/06/24 - I‚Äôm a sucker for nice polished UI and great UX. While there are a lot of Linux Desktop environments out there providing great UX and UI, I found GNOME to be the perfect one for my liking. Yes, I have seen/tried a few others. I also found some which are more polished and providing a better default UX out of the box than GNOME like Deepin and Elementary. But below plugins bridge that gap and hence I choose to stick with GNOME which is the default in Fedora, hence quite stable, unless I had a compelling reason to switch. So if you like me are a GNOME fan then below are some of the GNOME plugins you must try if you haven‚Äôt already. I have listed the plugins I use in my earlier post in the series. here I detail the ones that are a must-have. GNOME Tweaks: This nifty tool lets you tweak/configure a lot of GNOME configuration and should have been included by default in every distro shipping with GNOME. You can customize the appearance, install extensions, configure mouse &amp; keyboard and so on. It can be found in the software center of your distro. Search for ‚ÄúTweaks‚Äù.  Gnome extensions: You can install below extensions by visiting the link in the title of the extension below and by clicking on the on switch on the top right corner. On Chrome, you would need the GNOME Shell integration plugin to enable the switch. On Firefox, it will prompt you to install the plugin if it doesn‚Äôt exist. Dash to Dock: GNOME without this plugin almost feels annoying. IMO this plugin also should be the default GNOME setting. This one moves your GNOME dash into a highly configurable dock which can be placed on the sides or top/bottom of the screen. I find it perfect on the left side of the screen in GNOME. It can be a floating dock or fixed to look like those on Mint or KDE.  Always Zoom Workspaces: By default, the GNOME launcher does not show the workspaces, you have to hover over the right edge to see it. I find it unnecessary given you have enough real estate on the full-screen launcher and the workspace view takes only a little bit. This plugin keeps it zoomed by default.  Steal My Focus/NoAnnoyance: This is another default in GNOME that is annoying. When something needs focus these plugins brings the window up instead of the default notification. You can use any one of the plugins as both do the same thing. AlternateTab: This replaces the default Alt+Tab with a more classical window-based switcher which IMO is more user-friendly as the default requires more keyboard navigation using the arrow keys.  Window List: This is a classic plugin that adds the window list to the bottom of the screen and is a must if you use multiple monitors as the windows are grouped and placed in the right monitor screen. Caffeine: This one adds the ability to temporarily disable screensaver/auto-suspend and automatically activates when you go full-screen. A must-have if you are using your computer for watching videos, presentations, screencast and so on. Clipboard Indicator: This is one my favorite. It adds a nifty clipboard manager to the top bar and provides shortcuts to cycle through clipboard entries. A real time saver.  Gistnotes: As a developer using GitHub gist a lot, this one is a very useful plugin. It lets you manage your Gists right from the desktop and you can use it like a notes app.  System-monitor: A nice system monitor plugin that sits on the top bar with a detailed view as a popup.  TopIcons Plus: This moves legacy icons form applications to the top bar for consistent UX. I hope you find this useful. If you have any question or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Cover image photo by Brigitta Schneiter on Unsplash "
    }, {
    "id": 15,
    "url": "/my-beautiful-linux-development-environment/",
    "title": "My beautiful Linux development environment",
    "body": "2019/06/16 - One of the questions that I get quite often after a conference talk is weirdly not about what I presented but about my Linux desktop environment. People are more curious about that beautiful distro rather than the awesome presentation I just did üòÇ Not that I‚Äôm complaining, I love my desktop setup. I love it so much that I was afraid of getting a new PC when I was due for one. I was afraid that I would mess things up(I have done that many times in the past, I think Linux users can relate to me) So I decided to capture the most important aspects of my distro for anyone interested in using Linux as their primary OS for development.  This is not just my work laptop, it‚Äôs my primary machine which I use for all of the below  Java, JS, TS, Go, Python &amp; web development JHipster development Running multiple web applications locally Running Docker containers VirtualBox for Windows testing &amp; other VM stuff Kubernetes, Terraform, CloudFormation development and deployments Azure, AWS &amp; GCP deployments using required CLI tools Heavy browser usage Email, chat &amp; video conferencing Plex media server Blogging Youtube &amp; Social mediaMachine configuration: The configuration of the machine is also quite important for any development setup. So my laptop is a Dell Precision 5530 Mobile Workstation. I had the exact same setup with my old Dell 5510 as well, which is quite a similar configuration to 5530. I still have it as a backup Laptop, its 2 years old now but can still give most of the top end laptops today a run for its money. I used the custom configuration option from Dell to get the best possible setup at that time. it‚Äôs not cheap but my company, XebiaLabs, provided a handsome budget and I think it is worth every penny. This, in my opinion, is one of the best Laptop for developers. So here is what I have. Processor: Intel¬Æ Core‚Ñ¢ i9-8950HK CPU @ 2. 90GHz √ó 12 Memory: 32GB, DDR4-2666MHz SDRAM, 2 DIMMS, Non-ECC HDD: M. 2 1TB NVMe PCIe SED class 40 SSD Graphics: NVIDIA Quadro P2000 with 4 GB GDDR5 memory &amp; Intel¬Æ UHD Graphics 630 (Coffeelake 3x8 GT2) Wireless: Intel Wifi Link 9260 2x2 802. 11AC + BT 4. 2 vPro wireless card Keyboard: English QWERTY US, backlit Display: 15. 6‚Äù FHD 1920x1080 Anti-Glare LED-backlit Non-touch IPS UltraSharp‚Ñ¢ Battery: 6-cell (97Wh) Lithium Ion battery with ExpressCharge‚Ñ¢ Operating system and desktop environment: The most important of course is the operating system, I‚Äôm running Fedora 30 at the moment with GNOME 3. 32. 2 as the Desktop and I‚Äôm very happy with it. I find Fedora more suitable for development machines than other distros as it has a short release cycle and is fairly stable so you get latest &amp; stable software all the time.  What good is a desktop without a nice theme right? GNOME is great when it comes to themes and I went with Arc-Flatabulous theme and never looked back. For icons, I use Paper as I like the material icon theme.  Of course, it won‚Äôt be complete without some nice GNOME plugins. Below are the plugins that I use.  Dash to Dock Always Zoom Workspaces Auto Move Windows Native Window Placement Launch new instance Steal My Focus AlternateTab Window List Applications Menu Caffeine Clipboard Indicator Gistnotes OpenWeather Places Status Indicator System-monitor Todo. txt TopIcons Plus User ThemesDevelopment tools: Now, these are mostly objective choices and really doesn‚Äôt matter as long as you are comfortable with the tools you choose. Below are my choices for some of the important categories for development. I‚Äôm not including obvious things like Vim, Git, NodeJS, Docker, Kubernetes, etc. Shell: This is one of the most important for a developer. I use ZSH along with the awesome Oh My ZSH as my shell. Now, this won‚Äôt be complete without some nice plugins and theme. I use powerlevel9k theme with some customizations. I also use zsh-autosuggestions, git, docker, docker-compose, autojump, zsh-syntax-highlighting, dnf, and npm plugins for Oh My ZSH. Here is my . zshrc with all the customizations. Update: A comment on this post suggested powerlevel10k as an alternative theme and I tried it and turns out it is really way faster than powerlevel9k. So I think I‚Äôm gonna use powerlevel10k as my shell theme. Terminal: What good is a nice shell without a good terminal. Fortunately, we have Tilix one of the best terminal application out there. It has workspaces, tabs, split windows, Quake mode and so on.  Integrated development environment(IDE): IntelliJ IDEA ultimate - I use this only for Java &amp; other JVM language Development Code Editors: Visual Studio Code - My go-to editor. I love it. I use VSCode for web development, Go, Python, JS development, DevOps and everything other than JVM languages. A VSCode setup is never complete without some good plugins. Here are the plugins that I‚Äôm using. You can run the script to install those. Other notable development tools I use are GitKraken for Git repo management, Beyond Compare for code comparisons, VirtualBox, NVM for NodeJS version management and SDKMan for JDK version management. Productivity tools: Productivity tools are also quite important and below are my choices. Browser: Google Chrome is my primary browser. I also use Firefox &amp; Opera sometimes. I do love Opera in terms of its UX, I would love to use it as my primary browser but I miss everything I have synchronized with my Google account in Chrome. Email: I use Mailspring as my e-mail client. Its a fairly decent mail client with nice themes and a simple UI. Office suite: I mostly use Google Docs &amp; Microsoft office online but when I have to work on something on my Desktop I use LibreOffice which is a good office suite and even handles Microsoft Office &amp; Keynote formats. Communication: Of course I use Slack and for video conference I use BlueJeans. Screen capture: I use this nifty tool called Peek for screen recording and Shutter for screenshots. Conclusion: There are many other small and nifty utilities that I use, most are command line utilities. There are some notable mentions like Timeshift which is nice for backing up your machine. Of course, not everything is perfect in the Linux world, but it is the same with every OS. I was a long time Windows user before switching to Linux. So like every Linux users I have from time to time messed things up(With great power comes great responsibility, Peter). There are many quirks in the Linux world but there is nothing that bothers me much. Some of the most annoying issues I had in the past are below and for now, I don‚Äôt have any noticeable issues.  Scroll position jumping when switching apps - Fixed after upgrading to Fedora 30 Hibernation was broken - Fixed after upgrading to Fedora 30 Audio output selection was broken when plugging in headphones- Fixed after Fedora 28 for meThis has been a good day, upgraded to #Fedora 30 and hibernate started to work again. Sweet. I was putting off tinkering that for a long time. #Linux &mdash; ùîªùïñùïñùï°ùï¶ ùïÇ ùïäùïíùï§ùïöùïïùïôùïíùï£ùïíùïü (@deepu105) June 14, 2019I hope you find this useful. If you have any question or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. "
    }, {
    "id": 16,
    "url": "/why-im-moving-away-from-medium/",
    "title": "Why I‚Äôm moving away from Medium",
    "body": "2019/06/13 - After much deliberation, I have decided to move my blogs away from Medium. I was considering setting up my own blog with Hugo but then decided to go with Dev. to. Below are the reasons why I decided to leave Medium and why I chose Dev. to. All considerations were purely from a technical writing perspective as I was using Medium for publishing technical content. The love-hate relationship with Medium: I loved Medium when I started writing here, reasons being;    A simple minimal &amp; clean UI ‚Äî It still is one of the best     Ease of authoring and publishing     Community and visibility     Publications     Ease of customization  But there were also things I didn‚Äôt like much which slowly become quite annoying  The weird commenting mechanism(Every comment is a post, and they literally mess up your stories listing page)    Medium had a weird WYSIWYG editor interface which is great for normal content creation but not so great for technical content creation. It had some markdown like shortcuts, but it could never match the ease of using proper markdown editors.     Export only in HTML (Duh!!)  But these annoyances were not the main reason I decided to switch platforms. Below are the main reasons why I decided Medium isn‚Äôt a good fit for me. Medium has been aggressively pushing for content to be put behind a paywall and they have made it clear that content not opting in will not get any push inside the platform. This means the community and visibility part is applicable only if you opt-in for the paywall. I understand why Medium does and I think its a great monetary source for established authors but it doesn‚Äôt work for mere mortals like me.  As a result of the above, the traffic you get from Medium itself is very low compared to external sources. See one of my stories below for an example. For newer stories, it is even lower.  So writing in Medium seems to have no benefit over other platforms as I could get similar views from external sources and might get better writing experience elsewhere. UpdateSo after a week of moving to the Dev community below are my stats and its incredible, I have ~50k views, ~1k reactions and ~300 followers and one of my post was featured in top 7 of the week and all this in just 1 week. I didn‚Äôt get anything remotely close to this from Medium in a year.  Enter Dev. to: When I was trying to find a different platform, some of the most important aspects I considered were below    Community: A community without paywall and a community were your blogs get visibility and get traffic.     Ease of authoring: Authoring experience was important, hence at minimum Markdown support was a must. This way I can author posts in my favorite IDE(VsCode in this case) and doesn‚Äôt have to be restricted with the platform‚Äôs capability. Also, this ensures that I can easily move my posts to another platform in the future if needed.  Dev. to satisfied these needs and provided a nice and clean UI and descent publishing experience on top. Conclusion: I think Medium is still perfect for normal blogging and for content creators who have subscribers willing to pay even if they put articles behind a paywall. But for technical content creators who do not want their content behind a paywall, there are better platforms. I might still crosspost between Dev. to and Medium from time to time but Dev. to will be my primary blogging platform. Originally published in Medium on June 13, 2019 Cover image credit: Photo by MILKOV√ç on Unsplash "
    }, {
    "id": 17,
    "url": "/deploy-a-web-app-to-azure-app-service-using-terraform/",
    "title": "Deploy a web app to Azure App Service using Terraform",
    "body": "2019/06/12 - Deploying Java web applications to Azure is easy and has been tried, tested and explained many times by many people. My friend Julien Dubois has a nice series on it here. Azure makes it really easy to use its App Service as it provides many different ways of deploying a web app. If you are a modern full-stack Java developer there is a high chance that you are deploying your application as a Docker image. Hence today let‚Äôs see how we can deploy a Java web application to Azure App Service using Docker and Terraform in the true spirit of infrastructure as code. The approach is pretty much the same for any web application that is built as a docker image and not necessarily tied down to just Java. To try this out you would need to have Java, NodeJS, Terraform, Docker and Azure CLI installed. Follow the links to install them if needed. As one of the lead developer of JHipster (A handy development platform to generate, develop and deploy Spring Boot + Angular/React/Vue Web applications and Spring microservices), I would use a JHipster web application as the example here. So let‚Äôs get started. Let‚Äôs build a very simple web application using JHipster. We will use the JDL feature to scaffold our application. We will use the below JDL for our application. Save it to a file named app. jdl in a directory where you want to create the application. application {  config {    baseName helloJHipster,    applicationType monolith,    packageName tech. jhipster. demo,    authenticationType jwt,    buildTool gradle,    clientFramework react,    databaseType sql,    prodDatabaseType mysql,    languages [en, nl]  }}Now let us scaffold this using JHipster. Open your favorite console/terminal and run the below command in the directory where you saved the above JDL file, make sure it‚Äôs an empty directory. 1$ npx generator-jhipster import-jdl app. jdlIf you already have JHipster installed you can just run 1$ jhipster import-jdl app. jdlThis will scaffold the application and install the required client-side dependencies. It might take a few minutes(NPM!) so maybe its time for that coffee. You can see the application in action by running . /gradlew on the same terminal once the scaffolding is done. You can refer to the generated Readme. md for more instructions regarding the application. Now let‚Äôs move on to the focus of this post, deploying this to Azure App Service with Terraform. Let us first build and publish the docker image for our application. JHipster conveniently provides everything that is required to build docker images. Let us use the provided docker integration using JIB to build the images. Run the below Gradle command. 1$ . /gradlew bootJar -Pprod jibDockerBuildNow let us tag and push this to our docker registry, make sure you have logged into docker and run these commands. Use your own docker hub account name. 123$ docker tag hellojhipster:latest deepu105/hellojhipster:latest$ docker push deepu105/hellojhipster:latestYou can also push to Azure Container registry instead of Docker Hub if you like. Now that our application and Docker images are ready, let‚Äôs prepare the Terraform infrastructure for App Service and MySQL database. For other ways of deploying a JHipster web app to Azure check this out. First, create a folder for our terraform files. Let‚Äôs name the folder terraform. Now create three files called main. tf, outputs. tf, and variables. tf in this folder. Let us define the variables we will use. Save the below in variables. tf. 12345678910111213141516171819202122232425variable  prefix  { description =  The prefix used for all resources in this example  default   =  xl }variable  location  { description =  The Azure location where all resources in this example should be created }variable  subscription_id  { description =  Azure Subscription ID to be used for billing }variable  my_sql_master_password  { description =  MySql master password }variable  docker_image  { description =  Docker image name }variable  docker_image_tag  { description =  Docker image tag }Now let us define our main. tf First, let us add a configuration for Azure resource manager and create an Azure resource group to hold our resources. 123456789provider  azurerm  { version     =  =1. 24. 0  subscription_id =  ${var. subscription_id} }resource  azurerm_resource_group   main  { name   =  ${var. prefix}-resources  location =  ${var. location} }Now let us add the configuration to create a MySQL database server along with the required firewall rules to let App Service access the DB. If you want to add local access from your machine add a firewall rule block for your IP as well. 12345678910111213141516171819202122232425262728293031323334353637383940414243# This creates a MySQL serverresource  azurerm_mysql_server   main  { name        =  ${var. prefix}-mysql-server  location      =  ${azurerm_resource_group. main. location}  resource_group_name =  ${azurerm_resource_group. main. name}  sku {  name   =  B_Gen5_2   capacity = 2  tier   =  Basic   family  =  Gen5  } storage_profile {  storage_mb      = 5120  backup_retention_days = 7  geo_redundant_backup =  Disabled  } administrator_login     =  mysqladminun  administrator_login_password =  ${var. my_sql_master_password}  version           =  5. 7  ssl_enforcement       =  Disabled }# This is the database that our application will useresource  azurerm_mysql_database   main  { name        =  ${var. prefix}_mysql_db  resource_group_name =  ${azurerm_resource_group. main. name}  server_name     =  ${azurerm_mysql_server. main. name}  charset       =  utf8  collation      =  utf8_unicode_ci }# This rule is to enable the 'Allow access to Azure services' checkboxresource  azurerm_mysql_firewall_rule   main  { name        =  ${var. prefix}-mysql-firewall  resource_group_name =  ${azurerm_resource_group. main. name}  server_name     =  ${azurerm_mysql_server. main. name}  start_ip_address  =  0. 0. 0. 0  end_ip_address   =  0. 0. 0. 0 }This will create a MySQL server, a database for our app on the server and enable access from App Service. Now let us configure the App Service itself along with a service plan. 123456789101112131415161718192021222324252627282930313233343536373839# This creates the plan that the service useresource  azurerm_app_service_plan   main  { name        =  ${var. prefix}-asp  location      =  ${azurerm_resource_group. main. location}  resource_group_name =  ${azurerm_resource_group. main. name}  kind        =  Linux  reserved      = true sku {  tier =  Standard   size =  S1  }}# This creates the service definitionresource  azurerm_app_service   main  { name        =  ${var. prefix}-appservice  location      =  ${azurerm_resource_group. main. location}  resource_group_name =  ${azurerm_resource_group. main. name}  app_service_plan_id =  ${azurerm_app_service_plan. main. id}  site_config {  app_command_line =     linux_fx_version =  DOCKER|${var. docker_image}:${var. docker_image_tag}   always_on    = true } app_settings = {   WEBSITES_ENABLE_APP_SERVICE_STORAGE  =  false    DOCKER_REGISTRY_SERVER_URL      =  https://index. docker. io   # These are app specific environment variables   SPRING_PROFILES_ACTIVE    =  prod,swagger    SPRING_DATASOURCE_URL    =  jdbc:mysql://${azurerm_mysql_server. main. fqdn}:3306/${azurerm_mysql_database. main. name}?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false&amp;useLegacyDatetimeCode=false&amp;serverTimezone=UTC    SPRING_DATASOURCE_USERNAME  =  ${azurerm_mysql_server. main. administrator_login}@${azurerm_mysql_server. main. name}    SPRING_DATASOURCE_PASSWORD  =  ${var. my_sql_master_password}  }}In this configuration, under site_config we use linux_fx_version to declare our docker image and set always_on to true so that the application is not shut down when there is inactivity for some time. In the app_settings section we need to disable storage using the flag WEBSITES_ENABLE_APP_SERVICE_STORAGE and also specify DOCKER_REGISTRY_SERVER_URL. Everything else is specific to our app. The flags passed to the MySQL connection URL is important. Now that our main. tf is ready let us define some output properties that are handy. In the outputs. tf file add the below 1234567output  app_service_name  { value =  ${azurerm_app_service. main. name} }output  app_service_default_hostname  { value =  https://${azurerm_app_service. main. default_site_hostname} }Now we are ready to rock and roll! let us deploy the app. Make sure you have set up your Azure CLI and have logged in using az login. Now in a terminal/console navigate to the terraform folder we created and execute these commands. Please change the values for prefix, location &amp; docker_image accordingly. 1234567$ terraform init$ terraform apply \-var prefix=myAwesomeApp \-var location=northeurope \-var docker_image=deepu105/hellojhipster \-var docker_image_tag=latestThis will prompt you to enter a master password for MySQL server and your Azure subscription ID(You can find this from Azure portal or by running az account list- the id field is the subscription ID). Once you provide the values and confirm, Terraform will get to work and will start creating the resources. this could take a while since we are provisioning a Database server. Wait for it or go have that second coffee ;) Once the deployment is complete, Terraform will print out the outputs which include the app_service_default_hostname. Copy the URL and open it in your favorite browser. The first time could take a while since the app will be started(cold start) only during the first request.  I hope you found this useful. This is my first post in dev. to, I hope to migrate my blogs from Medium to dev. to soon. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. My other related posts:  Create full Microservice stack using JHipster Domain Language under 30 minutes Deploying JHipster Microservices on Azure Kubernetes Service (AKS) How to set up JHipster microservices with Istio service mesh on Kubernetes Continuous delivery of Microservices with XebiaLabs‚Ää‚Äî‚Ääa. k. a DevOps as Code"
    }, {
    "id": 18,
    "url": "/react-done-right-with-typescript/",
    "title": "React components done right with TypeScript mapped and conditional types",
    "body": "2018/11/19 - You‚Äôve probably heard about TypeScript, If not you should check it out. You may have heard someone claiming how great type safety is. TypeScript is great. As someone who hates to transpile his code, I would definitely do it with TypeScript if I had to. So much has been said about TypeScript, and there isn‚Äôt really anything new that I can add. But I do believe that type safety is not all about making your code ugly with type definitions everywhere. So how can we write type-safe code without having to litter type declarations everywhere? Type inference and advanced features like derived and dynamic types are the answer. Editors and IDEs we use are smart enough to handle code with inferred type gracefully without us having to see the types all the time visually. (Of course, they all usually show you the type when you hover over an inferred type. ) TypeScript has very good type inference. As a rule of thumb, you can always start without declaring the type for any variable and see if the compiler infers it. With modern editors like VSCode, you can see this immediately. So set your tsconfig to the strict mode. Then start declaring types when the compiler complains. Additionally, TypeScript 2. 1 and 2. 8 introduced a bunch of cool lookup types. Now you can dynamically infer types using different techniques like Intersection types, Union types, Index types, mapped types and conditional types. Index types: Index types enable us to check properties and types of an interface or type dynamically using the keyof T (index type query operator) and T[K] (indexed access operator). Let‚Äôs take the below interface for example. 123456  interface Person {   name: string;   age: number;   address: string;   sayHi: (msg: string) =&gt; string;  }The keyof T operator gets a union type of all the key names of the type T and hence keyof Person will give us 'name' | 'age' | 'address' | sayHi' as result. The T[K] operator gets the type for the provided key. Person['name'] will result in string and Person[*keyof* Person] will result in string | number | ((msg: string) =&gt; string). Mapped types: Let us see what mapped types are. Let us say we have the below interface for a Person. 123456  interface Person {   name: string;   age: number;   address: string;   sayHi: (msg: string) =&gt; string;  }Now in every project, it is almost always a common requirement to have variations of a certain interface. For example, let‚Äôs say we need a read-only version of the person as below. 123456  interface ReadonlyPerson {   readonly name: string;   readonly age: number;   readonly address: string;   readonly sayHi: (msg: string) =&gt; string;  }In this case, we would have to replicate the Person interface and we have to keep them in sync manually. This is where mapped types will come in handy, so let us use the builtin mapped type, Readonly, for this. 1  type ReadonlyPerson = Readonly&lt;Person&gt;If you hover over the ReadonlyPerson type you can see the inferred type as below. Inferred type view in VsCode That is cool, right? Now we can create types from existing types and don‚Äôt have to worry about keeping them in sync. How does it work, what does Readonly&lt;Person&gt; do? Let‚Äôs take a look at the mapped type. 123  type Readonly&lt;T&gt; = {    readonly [K in keyof T]: T[K];  }The in operator from TypeScript does the trick here. It maps all the declarations of the existing type into the new type. The keyof operator provides the keys from our type for the mapping. Let us build our own mapped type. Let us say we need a read-only Person interface where all the fields are nullable as well. We can build a mapped type as below for that. 123  type ReadonlyNullablePerson = {    readonly [P in keyof Person]: Person[P] | null;  }And it is inferred as below Let‚Äôs make it generic so that it can be used with any interface. 12345  type ReadonlyNullable&lt;T&gt; = {    readonly [K in keyof T]: T[K] | null;  }  type ReadonlyNullablePerson = ReadonlyNullable&lt;Person&gt;TypeScript includes Readonly&lt;T&gt;, Partial&lt;T&gt;, Pick&lt;T, K extends keyof T&gt; and Record&lt;K extends string, T&gt; as built-in mapped types. Pick and Record can be used as below, check them in your editor to see what types they produce. 123  type PersonMinimal = Pick&lt;Person, 'name' | 'age'&gt;  type RecordedPerson = Record&lt;'name' | 'address', string&gt;For every other use case, you can build your own mapped types. Conditional types:  A conditional type selects one of two possible types based on a condition expressed as a type relationship test. Let us look at an example. 1234567  type Foo&lt;T, U&gt; = T extends U ? string : boolean  interface Me {}  interface You extends Person {}  type FooBool = Foo&lt;Me, Person&gt; // will result in boolean  type FooString = Foo&lt;You, Person&gt; // will result in stringThe type dynamically inferred from Foo&lt;T, U&gt; will be either string or boolean depending on what the first generic is extended from. Let us see how we can mix conditional types with mapped types to infer a new type from Person which only includes the non-function properties. 123456789101112131415  type NonFunctionPropNames&lt;T&gt; = {   [K in keyof T]: T[K] extends Function ? never : K  }[keyof T];  type NonFunctionProps&lt;T&gt; = Pick&lt;T, NonFunctionPropNames&lt;T&gt;&gt;  type PersonProps = NonFunctionProps&lt;Person&gt;  /* Produces the below type  type PersonProps = {    name: string;    age: number;    address: string;  }  */We first get all the non-function property names from the interface. Then use the Pick mapped type to pick those from the interface to form the new interface. TypeScript provides the following inbuilt conditional types:    Exclude&lt;T, U&gt; ‚Äì Exclude from T those types that are assignable to U.     Extract&lt;T, U&gt; ‚Äì Extract from T those types that are assignable to U.     NonNullable&lt;T&gt; ‚Äì Exclude null and undefined from T.     ReturnType&lt;T&gt; ‚Äì Obtain the return type of a function type.     InstanceType&lt;T&gt; ‚Äì Obtain the instance type of a constructor function type.  Let us put it into use: These advanced types become even more powerful when you combine them together. Let‚Äôs see some practical uses of this in React. React component and Redux reducer in ES6: Let see a simple React component with a reducer written in ES6. Take a look at index. jsx in the below code sandbox:                         As you can see, we use the prop-types library to define the component props. It is not the most efficient way, as it includes considerable overhead during development. It doesn‚Äôt provide full type safety anyway. React component and Redux reducer in TypeScript: Now let us convert this simple example to TypeScript so that it is type safe. Take a look at index. tsx in the below code sandbox:                         As you can see, the code is more type-safe now. It is also much more verbose even without PropTypes library and all the type inference. React component and Redux reducer in TypeScript with advanced types: Now let us apply the advanced types that we learned to make this example less verbose and even more type safe. Take a look at index. tsx in the below code sandbox:                         As you can see, we used Readonly and ReturnType mapping along with some other type inference techniques to write a more type-safe but less verbose version of the component. Conclusion: If you are using React with TypeScript, then these are some of the techniques you must apply. If you are considering a type system for React, then look no further than TypeScript. It has great features, great tooling, excellent IDE/Editor support and an awesome community. I gave a talk on TypeScript for Devoxx 2018, and you can see the video and slides if you like here.                                                                         Check out my book ‚ÄúFull Stack Development with JHipster‚Äù on Amazon and Packt if you like to learn about Full stack development with an awesome stack that includes TypeScript and React. If you like JHipster don‚Äôt forget to give it a star on Github. If you like this article, please like or comment. You can follow me on Twitter and LinkedIn. Originally published in Medium on November 19, 2018 "
    }, {
    "id": 19,
    "url": "/deploying-jhipster-microservices-on-azure-kubernetes-service-aks/",
    "title": "Deploying JHipster Microservices on Azure Kubernetes Service (AKS)",
    "body": "2018/10/01 - If you are developing and deploying applications to production, especially cloud, you would have heard about Kubernetes. Kubernetes(k8s) is a container orchestration platform originally developed by Google and makes deploying containerized/dockerized applications to production more manageable and scalable. Kubernetes has been crowned as the undeniable champion of container orchestration for a while now and every other K*S offering that we see sprouting up are testimonials for that. The K obviously stands for Kubernetes and S/E stands for Service/Engine and the first letter stands for the product offering it. So far we have AKS(Azure), GKE(Google), and EKS(Amazon ECS) and PKS(Pivotal) and also some flavors from Oracle and RedHat(read Openshift) One of my colleagues have written a nice article about it, I highly recommend you read it as well. In this article, we will see how we can deploy a microservice architecture created by JHipster to Azure Kubernetes Service. Azure Kubernetes Service(AKS) is the managed Kubernetes platform offering from Microsoft to host your containerized applications. Creating the microservice application: In one of my previous posts, I showcased how to create a full stack microservice architecture using JHipster and JDL, read the post here if you want to learn more details about it. For this exercise, we will use the same application. Let us recap the steps required. Create a JDL file, let‚Äôs say app. jdl, and copy the below content into it. 400: Invalid requestNow create a directory called ecommerce and navigate into it. Run the JHipster import-jdl command. It could take a few minutes, especially the NPM install step. 12$ mkdir ecommerce &amp;&amp; cd ecommerce$ jhipster import-jdl app. jdlOnce the JHipster process is complete, you will see that we have our store gateway, invoice service and notification service created and ready for us. The process until this is explained in more detail in my previous post here and you can deploy the application locally using Docker as explained in that post. If you haven‚Äôt done that before I strongly suggest that step so that you get an idea of the application and you also can make sure it works locally on your machine. Generating the Kubernetes configuration: Now that our application is ready, let us create the required configurations for Kubernetes using JHipster. This can also be done using JDL by adding below snippet to the JDL file we used earlier. 123456789deployment { deploymentType kubernetes appsFolders [store, invoice, notification] serviceDiscoveryType eureka dockerRepositoryName  deepu105  // use your own docker repo username here kubernetesNamespace jhipster kubernetesServiceType LoadBalancer monitoring no}For now, let us use the JHipster CLI to do this. In the ecommerce folder, we created earlier, create a new directory, let‚Äôs call in k8s so that we get the below structure. 12345‚îú‚îÄ‚îÄ app. jdl‚îú‚îÄ‚îÄ invoice‚îú‚îÄ‚îÄ kubernetes‚îú‚îÄ‚îÄ notification‚îî‚îÄ‚îÄ storeCreate the kubernetes directory and navigate to it. Now run the JHipster Kubernetes command there. 12$ mkdir kubernetes &amp;&amp; cd kubernetes$ jhipster kubernetesThe generator will ask you a few questions and choose the answers as highlighted below, as you can see the questions are very similar to the ones asked by jhipster docker-compose command. For the ‚Äúbase Docker repository name‚Äù provide your own docker hub account id(For example, my Docker Hub id is deepu105). For real-world use cases, you could also use a private image repository like the Azure Container Registry and in that case, you would have to provide the ACR login server name here. For now, let us keep it simple. 12345678910111213141516171819202122232425262728‚éà Welcome to the JHipster Kubernetes Generator ‚éàFiles will be generated in folder: /home/deepu/workspace/temp/ecommerce/kubernetes‚úî Docker is installed? Which *type* of application would you like to deploy? Microservice application? Enter the root directory where your gateway(s) and microservices are located . . /3 applications found at /home/deepu/workspace/temp/ecommerce/? Which applications do you want to include in your configuration? invoice, notification, store? Do you want to setup monitoring for your applications ? No? Which applications do you want to use with clustered databases (only available with MongoDB and Couchbase)? JHipster registry detected as the service discovery and configuration provider used by your apps? Enter the admin password used to secure the JHipster Registry admin? What should we use for the Kubernetes namespace? jhipster? What should we use for the base Docker repository name? &lt;your Docker hub account id&gt;? What command should we use for push Docker image to repository? docker push? Do you want to enable Istio? No? Choose the kubernetes service type for your edge services LoadBalancer - Let a kubernetes cloud provider automatically assign an IPThe generator will go to work with this and will create the following files and output. 123456789101112131415161718192021222324252627282930313233343536373839404142  create invoice/invoice-deployment. yml  create invoice/invoice-service. yml  create invoice/invoice-mysql. yml  create notification/notification-deployment. yml  create notification/notification-service. yml  create notification/notification-mongodb. yml  create store/store-deployment. yml  create store/store-service. yml  create store/store-mysql. yml  create README. md  create registry/jhipster-registry. yml  create registry/application-configmap. yml  create kubectl-apply. shWARNING! Kubernetes configuration generated with missing images!To generate the missing Docker image(s), please run: . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/invoice . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/notification . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/storeWARNING! You will need to push your image to a registry. If you have not done so, use the following commands to tag and push the images: docker image tag invoice deepu105/invoice docker push deepu105/invoice docker image tag notification deepu105/notification docker push deepu105/notification docker image tag store deepu105/store docker push deepu105/storeYou can deploy all your apps by running the following script: . /kubectl-apply. shUse these commands to find your application's IP addresses: kubectl get svc storeCongratulations, JHipster execution is complete!As you can see the generator creates all the required Kubernetes configuration files and prints out useful information to proceed further (Note that the docker hub id you provided will be in the instructions in place of deepu105 here). Go through the generated k8s files and familiarize yourself. Now we are ready. Let us build and push the docker images for our application. Follow the instructions above and build docker images in each of the application folders and then tag and push the images to your Docker hub account. Preparing AKS Cluster: Now that our applications are built and pushed its time for us to deploy them to AKS. But before that let‚Äôs make sure we have all the prerequisites ready. You will need the below tools.    kubectl: The command line tool to interact with Kubernetes. Install and configure it.     Azure CLI: The command line tool to interact with Azure. Install and log in with your Azure account(You can create a free account if you don‚Äôt have one already).  Once the tools are ready let us prepare our Kubernetes cluster. First, let us create a resource group. Run the below command. This will create a resource group named eCommerceCluster in US east location(You can use other Azure regions as well). 1$ az group create --name eCommerceCluster --location eastusNow let us create an AKS cluster on the resource group we just created. Run the below command to create a cluster named eCommerceCluster with two nodes(We would need some room to run all those containers). It also enables the Azure monitor on the cluster through the add-on specified. 123$ az aks create --resource-group eCommerceCluster \--name eCommerceCluster --node-count 2 \--enable-addons monitoring --generate-ssh-keysThis would take several minutes to complete hence be patient and have a coffee :) Did I emphasize on several minutes? Once it‚Äôs done you should see the cluster information printed out as JSON. Now, let us configure kubectl to connect to the AKS cluster we just created. This can be done automatically using the Azure CLI by running the below handy command. Note: Some Azure CLI commands might take a while to execute, especially if you are on a slow network, sometimes if the below commands seem stalled or if it is timed out, kill it and retry again. 1$ az aks get-credentials --resource-group eCommerceCluster --name eCommerceClusterVerify that we are able to connect to the cluster by running kubectl get nodes 1234$ kubectl get nodesNAME            STATUS  ROLES   AGE    VERSIONaks-nodepool1-34429729-0  Ready   agent   22m    v1. 9. 9aks-nodepool1-34429729-1  Ready   agent   22m    v1. 9. 9Deploying the application to AKS: Now that our cluster is ready, let us deploy our microservice stack to this cluster. We can deploy our application using the kubectl apply command for this we have to navigate to the k8s folder we created earlier and run the below commands in the same order 1234567$ kubectl apply -f registry$ kubectl apply -f invoice$ kubectl apply -f notification$ kubectl apply -f storeOr you could also just run the handy kubectl-apply. sh script generated which runs the above. So we are deploying the JHipster Registry first as it is required for other services, followed by the microservices and finally our gateway(store). If you get a timeout during any of these, as I did, just try the command again. Though the services get created fast, the actual applications might not be up and running yet, give the entire thing a minute or two to start. Now run kubectl get pods to see the status of our containers. 1234567891011$ kubectl get pods -wNAME                  READY STATUS invoice-5ffb46d944-h8x42        1/1  Runninginvoice-mysql-66bc4b7874-p7ghk     1/1  Runningjhipster-registry-0           1/1  Runningjhipster-registry-1           1/1  Runningnotification-76847b7667-d7xjb      1/1  Runningnotification-mongodb-6db986b556-8bw8z  1/1  Runningstore-8dc5cd6f7-s2dpx          1/1  Runningstore-mysql-779d66685d-tmkqd      1/1  RunningNote: I have removed some info for brevity in the above output. Wait until all the containers are in Running status. Once the containers are running we can run the kubectl get service command to get the external IP for the application. 1234$ kubectl get service storeNAME  TYPE     CLUSTER-IP  EXTERNAL-IP  PORT(S)     AGEstore LoadBalancer 10. 0. 189. 145 40. 117. 140. 228 8080:30143/TCP 18mIn this case, the external IP for our gateway application is 40. 117. 140. 228 running on port 8080. Let us open it up in a web browser. The Gateway application login page The JHipster registry is deployed as a headless service by default. If we need to access the registry we need to create a secondary service with a Load Balancer. Run the below command to expose the second service. 1$ kubectl expose service jhipster-registry --type=LoadBalancer --name=exposed-registryNow run the kubectl get service command to get the IP. 1234$ kubectl get service exposed-registryNAME       TYPE     CLUSTER-IP  EXTERNAL-IP  PORT(S)exposed-registry LoadBalancer 10. 0. 107. 121 104. 211. 15. 142 8761:32628/TCPVisit the URL in a browser to see the registry in action JHipster Registry home page We can now scale any of our services by simply running kubectl scale command. For example, let us scale our Invoice service. 1$ kubectl scale --replicas=2 deployment/invoiceNow we can visit the Eureka -&gt; Instances on our Registry and see that the Invoice service has two instances. JHipster Registry instances page Running kubectl get pods will also show you the new instance. 123456789101112$ kubectl get pods NAME                 READY STATUS  AGEinvoice-5ffb46d944-g8j6j       1/1  Running 4minvoice-5ffb46d944-h8x42       1/1  Running 2hinvoice-mysql-66bc4b7874-p7ghk    1/1  Running 2hjhipster-registry-0          1/1  Running 2hjhipster-registry-1          1/1  Running 2hnotification-76847b7667-d7xjb     1/1  Running 2hnotification-mongodb-6db986b556-8bw8z 1/1  Running 2hstore-8dc5cd6f7-s2dpx         1/1  Running 2hstore-mysql-779d66685d-tmkqd     1/1  Running 2hThat is it, we have successfully got our application deployed to AKS and scaled our service on demand. Cleanup: Once you are done its always a good idea to clean up especially since we don‚Äôt want to keep unnecessary resources that might eat up our free credits on Azure. Let us delete the cluster from AKS and related resources created by deleting the entire resource group. 1$ az group delete --name eCommerceCluster --yes --no-waitCluster related activities like creation/update/deletion could take several minutes on AKS so we have to be patient again here. Conclusion: Kubernetes is definitely the best way to deploy microservice applications to production but creating and managing Kubernetes clusters itself is not an easy task, but Kubernetes services like GKE and AKS makes it a cakewalk. In my personal experience, the Kubernetes service from Google(GKE) and Azure(AKS) are by far the best in terms of ease of use and available tooling. These services provide very handy command line tools which work nicely together with kubectl to provide a very nice experience. They also have nice UI portals if you are not a fan of the CLI. JHipster provides a great Kubernetes setup to start with which you can further tweak as per your needs and platform. In upcoming posts, we will look at more services like GKE(Google), EKS(Amazon) and Openshift(RedHat) To learn more about JHipster, check out my book ‚ÄúFull Stack Development with JHipster‚Äù on Amazon and Packt. If you like JHipster don‚Äôt forget to give it a star on Github. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. My other related posts:    Create full Microservice stack using JHipster Domain Language under 30 minutes     JHipster microservices with Istio service mesh on Kubernetes  Originally published in Medium on Oct 01, 2018 "
    }, {
    "id": 20,
    "url": "/create-full-microservice-stack-using-j-hipster-domain-language-under-30-minutes/",
    "title": "Create full Microservice stack using JHipster Domain Language under 30 minutes",
    "body": "2018/09/22 - It‚Äôs been quite a while since I wrote a blog, I did a few some years ago but never really continued writing. So when I decided to start writing again, I didn‚Äôt have to think a lot about a topic as it was very obvious ‚Äî JHipster. JHipster is a development platform for Java web applications and microservices development. If you are a JVM developer you might have already heard about JHipster. If not, well, you are missing out on a lot and I highly recommend you check it out. You can also check out my book ‚ÄúFull Stack Development with JHipster‚Äù on Amazon and Packt to learn about JHipster. I have been working on JHipster from April 2015 and the coolest feature that I got to implement so far is definitely multiple applications generation using JDL. This feature is available in the latest version of JHipster. If you are not familiar with JDL, I recommend you to check out the docs at https://www. jhipster. tech/jdl/ The E-Commerce application: So let us see how we can create a microservice stack using JHipster. We will build an e-commerce store today. The stack includes-    Service discovery using JHipster Registry, a Spring boot application that packs Eureka server and Spring cloud config server.     API management and Gateway using Spring Boot, Netflix Zuul, ReactJS, and Swagger.     Microservices using Spring Boot.     Monitoring using JHipster Console which is made of the Elastic stack(ELK) and Zipkin.  Microservice application architecture The Gateway routes incoming requests to two microservices, Invoice application, and Notification application. Requirements: In order to follow this tutorial, you would need a recent version of Docker, Docker-compose, NodeJS and Java installed on your computer. The below are the versions I have installed(Update: With JHipster 6+ you can use Java 11 &amp; 12). 12345678910111213$ docker -v                                                            Docker version 18. 06. 1-ce, build e68fc7a$ docker-compose -v                docker-compose version 1. 20. 1, build 5d8c71b$ node -v        v8. 11. 4$ java -version     openjdk version  1. 8. 0_212 OpenJDK Runtime Environment (Zulu 8. 38. 0. 13-CA-linux64) (build 1. 8. 0_212-b04)OpenJDK 64-Bit Server VM (Zulu 8. 38. 0. 13-CA-linux64) (build 25. 212-b04, mixed mode)First, install the latest version of JHipster 1$ npm install generator-jhipster -gVerify that you have version 5. 3. 4 or above by running 1$ jhipster --versionCreating the JDL: Now let us create our JDL. Head over to the JDL Studio or your favorite IDE/Editor(You can use JHipster IDE plugin if you like). First, let us define our applications. We will start with the Gateway 123456789101112131415application { config {  baseName store,  applicationType gateway,  packageName com. jhipster. demo. store,  serviceDiscoveryType eureka,  authenticationType jwt,  prodDatabaseType mysql,  cacheProvider hazelcast,  buildTool gradle,  clientFramework react,  testFrameworks [protractor] } entities *}Most of the options are self-explanatory, we are building an application named Store of type Gateway with JWT authentication and Eureka-based service discovery. The application uses a MySQL database and Hazelcast for the cache. It‚Äôs built using Gradle. For the client-side, it uses React and Sass. It also has Protractor for end-to-end testing. At the end of the definition you can see entities *, we will come to this later. Now let us define our Invoice microservice 12345678910111213application { config {  baseName invoice,  applicationType microservice,  packageName com. jhipster. demo. invoice,  serviceDiscoveryType eureka,  authenticationType jwt,  prodDatabaseType mysql,  buildTool gradle,  serverPort 8081 } entities Invoice, Shipment}It follows similar options like our Gateway and since it is microservice it doesn‚Äôt define any client-side options and also skips user management as it will be handled by the Gateway. Additionally, we have also mentioned a custom port 8081 since we do not want this application to conflict with the default port 8080 used by the Gateway. Now let us define the second microservice, the Notification application 123456789101112131415application { config {  baseName notification,  applicationType microservice,  packageName com. jhipster. demo. notification,  serviceDiscoveryType eureka,  authenticationType jwt,  databaseType mongodb,  cacheProvider no,  enableHibernateCache false,  buildTool gradle,  serverPort 8082 } entities Notification}This application follows many options similar to the Gateway and Invoice application but instead of using MySQL it uses MongoDB as its database and also disables cache. Now that our application definitions are done, we will proceed to define our entity model. For our Gateway store application, let us define the below entities and enums 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** Product sold by the Online store */entity Product {  name String required  description String  price BigDecimal required min(0)  size Size required  image ImageBlob}enum Size {  S, M, L, XL, XXL}entity ProductCategory {  name String required  description String}entity Customer {  firstName String required  lastName String required  gender Gender required  email String required pattern(/^[^@\s]+@[^@\s]+\. [^@\s]+$/)  phone String required  addressLine1 String required  addressLine2 String  city String required  country String required}enum Gender {  MALE, FEMALE, OTHER}entity ProductOrder {  placedDate Instant required  status OrderStatus required  code String required  invoiceId Long}enum OrderStatus {  COMPLETED, PENDING, CANCELLED}entity OrderItem {  quantity Integer required min(0)  totalPrice BigDecimal required min(0)  status OrderItemStatus required}enum OrderItemStatus {  AVAILABLE, OUT_OF_STOCK, BACK_ORDER}relationship OneToOne {  Customer{user(login) required} to User}relationship ManyToOne {  OrderItem{product(name) required} to Product}relationship OneToMany {  Customer{order} to ProductOrder{customer(email) required},  ProductOrder{orderItem} to OrderItem{order(code) required},  ProductCategory{product} to Product{productCategory(name)}}service Product, ProductCategory, Customer, ProductOrder, OrderItem with serviceClasspaginate Product, Customer, ProductOrder, OrderItem with paginationThe JDL defines the entities, enums, the relationship between entities and options like pagination and service layer. The entity field definition follows the syntax 123entity &lt;entity name&gt; { &lt;field name&gt; &lt;type&gt; [&lt;validation&gt;*]}The relationship definition follows the syntax 12345relationship (OneToMany | ManyToOne | OneToOne | ManyToMany) {  &lt;from entity&gt;[{&lt;relationship name&gt;[(&lt;display field&gt;)]}]   to   &lt;to entity&gt;[{&lt;relationship name&gt;[(&lt;display field&gt;)]}]}Refer the JDL docs for full DSL reference. The Invoice microservice application has the following entities 12345678910111213141516171819202122232425262728293031entity Invoice {  code String required  date Instant required  details String  status InvoiceStatus required  paymentMethod PaymentMethod required  paymentDate Instant required  paymentAmount BigDecimal required}enum InvoiceStatus {  PAID, ISSUED, CANCELLED}entity Shipment {  trackingCode String  date Instant required  details String}enum PaymentMethod {  CREDIT_CARD, CASH_ON_DELIVERY, PAYPAL}relationship OneToMany {  Invoice{shipment} to Shipment{invoice(code) required}}service Invoice, Shipment with serviceClasspaginate Invoice, Shipment with paginationmicroservice Invoice, Shipment with invoicePay attention to the last microservice option declared here, it specifies that these entities belong to the microservice named invoice so that our Gateway knows where to route requests for these entities. Now let us see the entities for the Notification microservice application 1234567891011121314entity Notification {  date Instant required  details String  sentDate Instant required  format NotificationType required  userId Long required  productId Long required}enum NotificationType {  EMAIL, SMS, PARCEL}microservice Notification with notificationNow let us go back to the entities keyword we used in our application definitions. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061application { config {  . . .  } entities *}application { config {  . . .  } entities Invoice, Shipment}application { config {  . . .  } entities Notification}/* Entities for Store Gateway */entity Product {  . . . }entity ProductCategory {  . . . }entity Customer {  . . . }entity ProductOrder {  . . . }entity OrderItem {  . . . }microservice Invoice, Shipment with invoice/* Entities for Invoice microservice */entity Invoice {  . . . }entity Shipment {  . . . }/* Entities for notification microservice */entity Notification {  . . . }microservice Notification with notificationHere we instruct the store gateway application that it should contain all the entities defined in the JDL and the gateway will know to skip server-side code for the entities that belong to another microservice and hence will only generate the client-side code for those, here namely Invoice, Shipment, and Notification. We also instruct the Invoice application and Notification application to include its entities. Generating the applications: Create a folder where we want to create our microservice stack. 1$ mkdir ecommerce &amp;&amp; cd ecommerceNow, let us put everything together into a JDL file. Let us call it app. jdl and save it into this folder. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169application { config {  baseName store,  applicationType gateway,  packageName com. jhipster. demo. store,  serviceDiscoveryType eureka,  authenticationType jwt,  prodDatabaseType mysql,  cacheProvider hazelcast,  buildTool gradle,  clientFramework react,  testFrameworks [protractor] } entities *}application { config {  baseName invoice,  applicationType microservice,  packageName com. jhipster. demo. invoice,  serviceDiscoveryType eureka,  authenticationType jwt,  prodDatabaseType mysql,  buildTool gradle,  serverPort 8081 } entities Invoice, Shipment}application { config {  baseName notification,  applicationType microservice,  packageName com. jhipster. demo. notification,  serviceDiscoveryType eureka,  authenticationType jwt,  databaseType mongodb,  cacheProvider no,  enableHibernateCache false,  buildTool gradle,  serverPort 8082 } entities Notification}/* Entities for Store Gateway *//** Product sold by the Online store */entity Product {  name String required  description String  price BigDecimal required min(0)  size Size required  image ImageBlob}enum Size {  S, M, L, XL, XXL}entity ProductCategory {  name String required  description String}entity Customer {  firstName String required  lastName String required  gender Gender required  email String required pattern(/^[^@\s]+@[^@\s]+\. [^@\s]+$/)  phone String required  addressLine1 String required  addressLine2 String  city String required  country String required}enum Gender {  MALE, FEMALE, OTHER}entity ProductOrder {  placedDate Instant required  status OrderStatus required  code String required  invoiceId Long}enum OrderStatus {  COMPLETED, PENDING, CANCELLED}entity OrderItem {  quantity Integer required min(0)  totalPrice BigDecimal required min(0)  status OrderItemStatus required}enum OrderItemStatus {  AVAILABLE, OUT_OF_STOCK, BACK_ORDER}relationship OneToOne {  Customer{user(login) required} to User}relationship ManyToOne { OrderItem{product(name) required} to Product}relationship OneToMany {  Customer{order} to ProductOrder{customer(email) required},  ProductOrder{orderItem} to OrderItem{order(code) required} ,  ProductCategory{product} to Product{productCategory(name)}}service Product, ProductCategory, Customer, ProductOrder, OrderItem with serviceClasspaginate Product, Customer, ProductOrder, OrderItem with pagination/* Entities for Invoice microservice */entity Invoice {  code String required  date Instant required  details String  status InvoiceStatus required  paymentMethod PaymentMethod required  paymentDate Instant required  paymentAmount BigDecimal required}enum InvoiceStatus {  PAID, ISSUED, CANCELLED}entity Shipment {  trackingCode String  date Instant required  details String}enum PaymentMethod {  CREDIT_CARD, CASH_ON_DELIVERY, PAYPAL}relationship OneToMany {  Invoice{shipment} to Shipment{invoice(code) required}}service Invoice, Shipment with serviceClasspaginate Invoice, Shipment with paginationmicroservice Invoice, Shipment with invoice/* Entities for notification microservice */entity Notification {  date Instant required  details String  sentDate Instant required  format NotificationType required  userId Long required  productId Long required}enum NotificationType {  EMAIL, SMS, PARCEL}microservice Notification with notificationNow let us invoke JHipster CLI to import this file 1$ jhipster import-jdl app. jdlThis will create the store, invoice and notification folders and will do the below in each of the folders    Generate the appropriate application and entities configuration.     Generate the application and entities source code based on the configurations.     Install the NPM dependencies for the application.  Once the process is complete you should see the below on your console 123456789Entity Product generated successfully. Entity ProductCategory generated successfully. Entity Customer generated successfully. Entity ProductOrder generated successfully. Entity OrderItem generated successfully. Entity Invoice generated successfully. Entity Shipment generated successfully. Entity Notification generated successfully. Congratulations, JHipster execution is complete!Walk around the generated code to familiarize yourself. Running the applications with Docker: Now that our applications are created its time to test them locally using Docker. To do this first let us generate some docker compose configurations using JHipster. Create a new folder inside the ecommerce folder and run the JHipster docker-compose command 12$ mkdir docker-compose &amp;&amp; cd docker-compose$ jhipster docker-composeIt will prompt you with a few questions, choose the answers as highlighted below 12345678910111213141516171819202122üê≥ Welcome to the JHipster Docker Compose Sub-Generator üê≥Files will be generated in folder: /home/deepu/workspace/temp/ecommerce/docker-compose‚úî Docker is installed? Which *type* of application would you like to deploy? Microservice application? Which *type* of gateway would you like to use? JHipster gateway based on Netflix Zuul? Enter the root directory where your gateway(s) and microservices are located . . /3 applications found at /home/deepu/workspace/temp/ecommerce/? Which applications do you want to include in your configuration? invoice, notification, store? Which applications do you want to use with clustered databases (only available with MongoDB and Couchbase)? ? Do you want to setup monitoring for your applications ? Yes, for logs and metrics with the JHipster Console (based on ELK and Zipkin)? You have selected the JHipster Console which is based on the ELK stack and additional technologies, which one do you want to use ? Zipkin, for distributed tracing (only compatible with JHipster &gt;= v4. 2. 0)JHipster registry detected as the service discovery and configuration provider used by your apps? Enter the admin password used to secure the JHipster Registry? adminThis will generate all the required docker-compose configurations for the stack and will also print out further instructions to build the docker images. Note: In the latest JHipster versions we migrated to using Jib for creating Docker images. This is a huge improvement over the Docker Maven plugin that we were using, as a result the command to create an image has changed to . /gradlew -Pprod bootWar jibDockerBuild. 12345Docker Compose configuration generated with missing images!To generate the missing Docker image(s), please run: . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/invoice . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/notification . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/storeFollow the instructions and build the docker images. Once all 3 images are built run the below command from the docker-compose folder to fire everything up. 1$ docker-compose up -dOnce the containers start you can stream the logs using below command 1$ docker-compose logs -fNow point your favorite browser to http://localhost:8080/ and see the E-Commerce microservice application in action. Gateway application(Store) You can see the JHipster registry in action at http://localhost:8761/ JHipster Registry And finally the JHipster console at http://localhost:5601/ JHipster Console- Kibana dashboard Once you are done playing around, you can shut everything down by running the below command on the docker-compose folder 1docker-compose downHope you had fun creating microservices using JHipster. To learn how to convert a JHipster monolith to microservices check out my book ‚ÄúFull Stack Development with JHipster‚Äù on Amazon and Packt. In the coming weeks, I‚Äôll write some posts about deploying this microservice stack to various cloud providers like GCP, Azure, AWS, Heroku and so on. If you like JHipster don‚Äôt forget to give it a star on Github. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. My other related posts:    Deploying JHipster Microservices on Azure Kubernetes Service (AKS)     JHipster microservices with Istio service mesh on Kubernetes  Originally published in Medium on Sep 22, 2018 "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}

function lunr_search(term) {
    $('#lunrsearchresults').show( 400 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-danger btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
    
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 5 );
        $( "body" ).removeClass( "modal-open" );
    });
});